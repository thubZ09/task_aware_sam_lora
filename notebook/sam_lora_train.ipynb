{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":12509488,"sourceType":"datasetVersion","datasetId":7895689}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#patching segment_anything.mask_decoder to support 5‑D src tensors\nimport glob, re, os\n\ncands = glob.glob(\"/usr/local/lib/python3.*/dist-packages/segment_anything/modeling/mask_decoder.py\")\nif not cands:\n    raise FileNotFoundError(\"Can't find segment_anything/modeling/mask_decoder.py\")\ndecoder = cands[0]\nprint(\"Patching:\", decoder)\n\n#read & patch\nwith open(decoder, \"r\") as f:\n    lines = f.readlines()\n\npatched = []\nfor line in lines:\n    #replace 4‑D unpack with 5‑D + collapse\n    if re.match(r\"\\s*b, c, h, w = src\\.shape\", line):\n        indent = line[:line.index(\"b\")]\n        patched += [\n            f\"{indent}# accommodate extra token dim\\n\",\n            f\"{indent}b, t, c, h, w = src.shape\\n\",\n            f\"{indent}src = src.view(b * t, c, h, w)\\n\",\n            f\"{indent}pos_src = pos_src.view(b * t, c, h, w)\\n\",\n        ]\n    else:\n        patched.append(line)\n\nfinal = []\nfor line in patched:\n    if line.strip() == \"return masks, iou_pred\":\n        indent = line[:line.index(\"return\")]\n        final += [\n            f\"{indent}# reshape masks and iou back to [B, T, …]\\n\",\n            f\"{indent}masks = masks.view(b, t, 1, h, w)\\n\",\n            f\"{indent}iou_pred = iou_pred.view(b, t)\\n\",\n        ]\n        final.append(line)\n    else:\n        final.append(line)\n\nwith open(decoder, \"w\") as f:\n    f.writelines(final)\n\nprint(\"Patched segment_anything.mask_decoder – now restart the kernel.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:31:03.340652Z","iopub.execute_input":"2025-07-19T04:31:03.340864Z","iopub.status.idle":"2025-07-19T04:31:03.358981Z","shell.execute_reply.started":"2025-07-19T04:31:03.340836Z","shell.execute_reply":"2025-07-19T04:31:03.358221Z"}},"outputs":[{"name":"stdout","text":"Patching: /usr/local/lib/python3.11/dist-packages/segment_anything/modeling/mask_decoder.py\nPatched segment_anything.mask_decoder – now restart the kernel.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"PROJECT_PATH = \"/kaggle/input/task-aware-sam-lora/task_aware_sam_lora\"\nimport sys, os\nsys.path.append(PROJECT_PATH)\n\n!pip install -q transformers accelerate opencv-python matplotlib wandb datasets fsspec==2023.9.2 pycocotools\n\nSAM_CKPT_PATH = \"/kaggle/working/sam_vit_h_4b8939.pth\"\nif not os.path.exists(SAM_CKPT_PATH):\n    !wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P /kaggle/working/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T06:01:17.472035Z","iopub.execute_input":"2025-07-19T06:01:17.472653Z","iopub.status.idle":"2025-07-19T06:01:21.169262Z","shell.execute_reply.started":"2025-07-19T06:01:17.472619Z","shell.execute_reply":"2025-07-19T06:01:21.168232Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T06:01:25.943189Z","iopub.execute_input":"2025-07-19T06:01:25.944091Z","iopub.status.idle":"2025-07-19T06:01:25.949992Z","shell.execute_reply.started":"2025-07-19T06:01:25.944059Z","shell.execute_reply":"2025-07-19T06:01:25.949238Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nGPU: Tesla T4\nGPU Memory: 14.7 GB\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from src.models.hypernetwork import TaskAwareHyperNet, create_sam_lora_config\nfrom src.models.lora_adapter import LoRAAdapter, LoRAConfig\nfrom src.models.sam_wrapper import SAMWithLoRA, TaskAwareSAM\nfrom src.data.dataset import TaskAwareDataset\nfrom src.utils.text_processing import TaskDescriptionProcessor\nfrom config.train_config import get_t4_optimized_config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T06:01:29.249856Z","iopub.execute_input":"2025-07-19T06:01:29.250771Z","iopub.status.idle":"2025-07-19T06:01:29.255210Z","shell.execute_reply.started":"2025-07-19T06:01:29.250726Z","shell.execute_reply":"2025-07-19T06:01:29.254236Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#config initialization\n#load config\nbase_cfg   = get_t4_optimized_config()\nmodel_cfg  = base_cfg.model\nsystem_cfg = base_cfg.system\n\n#LoRA adapter config\nlora_cfg = LoRAConfig(\n    rank=model_cfg.lora_rank,\n    alpha=model_cfg.lora_alpha,\n    dropout=model_cfg.lora_dropout,\n    target_modules=model_cfg.lora_target_modules\n)\n\n#SAM + LoRA\nsam_model = SAMWithLoRA(\n    sam_checkpoint=SAM_CKPT_PATH,\n    model_type=model_cfg.sam_model_type, \n    lora_config=lora_cfg,\n    device=device\n)\n\n#hypernetwork\nlora_config_dict = create_sam_lora_config(sam_model.sam.mask_decoder)\nhypernet = TaskAwareHyperNet(\n    lora_config=lora_config_dict,\n    lora_rank=model_cfg.lora_rank,\n    text_encoder_model=model_cfg.text_encoder_model,\n    hidden_dim=model_cfg.hypernetwork_hidden_dim,\n    num_layers=model_cfg.hypernetwork_num_layers,\n    num_heads=model_cfg.hypernetwork_num_heads,\n    dropout=model_cfg.hypernetwork_dropout\n).to(device)\n\ntext_processor = TaskDescriptionProcessor()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:33:47.040172Z","iopub.execute_input":"2025-07-19T04:33:47.041233Z","iopub.status.idle":"2025-07-19T04:34:17.805982Z","shell.execute_reply.started":"2025-07-19T04:33:47.041205Z","shell.execute_reply":"2025-07-19T04:34:17.805281Z"}},"outputs":[{"name":"stdout","text":"Frozen SAM encoders\nAdded LoRA to: output_hypernetworks_mlps.0.layers.0 (as output_hypernetworks_mlps_0_layers_0)\nAdded LoRA to: output_hypernetworks_mlps.0.layers.1 (as output_hypernetworks_mlps_0_layers_1)\nAdded LoRA to: output_hypernetworks_mlps.0.layers.2 (as output_hypernetworks_mlps_0_layers_2)\nAdded LoRA to: output_hypernetworks_mlps.1.layers.0 (as output_hypernetworks_mlps_1_layers_0)\nAdded LoRA to: output_hypernetworks_mlps.1.layers.1 (as output_hypernetworks_mlps_1_layers_1)\nAdded LoRA to: output_hypernetworks_mlps.1.layers.2 (as output_hypernetworks_mlps_1_layers_2)\nAdded LoRA to: output_hypernetworks_mlps.2.layers.0 (as output_hypernetworks_mlps_2_layers_0)\nAdded LoRA to: output_hypernetworks_mlps.2.layers.1 (as output_hypernetworks_mlps_2_layers_1)\nAdded LoRA to: output_hypernetworks_mlps.2.layers.2 (as output_hypernetworks_mlps_2_layers_2)\nAdded LoRA to: output_hypernetworks_mlps.3.layers.0 (as output_hypernetworks_mlps_3_layers_0)\nAdded LoRA to: output_hypernetworks_mlps.3.layers.1 (as output_hypernetworks_mlps_3_layers_1)\nAdded LoRA to: output_hypernetworks_mlps.3.layers.2 (as output_hypernetworks_mlps_3_layers_2)\nAdded LoRA to 12 layers\nSAM with LoRA initialized:\n  Model type: vit_h\n  LoRA parameters: 20,992\n  Device: cuda\nAdded LoRA to: output_hypernetworks_mlps.0.layers.0 (256→256)\nAdded LoRA to: output_hypernetworks_mlps.0.layers.1 (256→256)\nAdded LoRA to: output_hypernetworks_mlps.0.layers.2 (256→32)\nAdded LoRA to: output_hypernetworks_mlps.1.layers.0 (256→256)\nAdded LoRA to: output_hypernetworks_mlps.1.layers.1 (256→256)\nAdded LoRA to: output_hypernetworks_mlps.1.layers.2 (256→32)\nAdded LoRA to: output_hypernetworks_mlps.2.layers.0 (256→256)\nAdded LoRA to: output_hypernetworks_mlps.2.layers.1 (256→256)\nAdded LoRA to: output_hypernetworks_mlps.2.layers.2 (256→32)\nAdded LoRA to: output_hypernetworks_mlps.3.layers.0 (256→256)\nAdded LoRA to: output_hypernetworks_mlps.3.layers.1 (256→256)\nAdded LoRA to: output_hypernetworks_mlps.3.layers.2 (256→32)\nAdded LoRA to: iou_prediction_head.layers.0 (256→256)\nAdded LoRA to: iou_prediction_head.layers.1 (256→256)\nAdded LoRA to: iou_prediction_head.layers.2 (256→4)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"454bd638653b4e55a50b850f8fb27b35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d062d7361a947bb96262fc91f794074"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78c78674c83a4cc5aefdbcf41800b6c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b79fed61fefd41a0942583c64256b060"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db29aa5d407a48d085f938b812c7f56b"}},"metadata":{}},{"name":"stderr","text":"2025-07-19 04:34:04.626799: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752899644.848224      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752899644.909247      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6dd26ddcbb4817883ae73a05d5ca99"}},"metadata":{}},{"name":"stdout","text":"TaskAwareHyperNet initialized with 26128 LoRA parameters\n  output_hypernetworks_mlps.0.layers.0: 256x256, LoRA A: 1024, LoRA B: 1024\n  output_hypernetworks_mlps.0.layers.1: 256x256, LoRA A: 1024, LoRA B: 1024\n  output_hypernetworks_mlps.0.layers.2: 256x32, LoRA A: 1024, LoRA B: 128\n  output_hypernetworks_mlps.1.layers.0: 256x256, LoRA A: 1024, LoRA B: 1024\n  output_hypernetworks_mlps.1.layers.1: 256x256, LoRA A: 1024, LoRA B: 1024\n  output_hypernetworks_mlps.1.layers.2: 256x32, LoRA A: 1024, LoRA B: 128\n  output_hypernetworks_mlps.2.layers.0: 256x256, LoRA A: 1024, LoRA B: 1024\n  output_hypernetworks_mlps.2.layers.1: 256x256, LoRA A: 1024, LoRA B: 1024\n  output_hypernetworks_mlps.2.layers.2: 256x32, LoRA A: 1024, LoRA B: 128\n  output_hypernetworks_mlps.3.layers.0: 256x256, LoRA A: 1024, LoRA B: 1024\n  output_hypernetworks_mlps.3.layers.1: 256x256, LoRA A: 1024, LoRA B: 1024\n  output_hypernetworks_mlps.3.layers.2: 256x32, LoRA A: 1024, LoRA B: 128\n  iou_prediction_head.layers.0: 256x256, LoRA A: 1024, LoRA B: 1024\n  iou_prediction_head.layers.1: 256x256, LoRA A: 1024, LoRA B: 1024\n  iou_prediction_head.layers.2: 256x4, LoRA A: 1024, LoRA B: 16\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#transforms/loader\nfrom torchvision import transforms\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)), \n    transforms.ToTensor(),\n])\n\nCOCO_DIR = \"/kaggle/input/coco-2017-dataset/coco2017\"\ncoco_dataset = TaskAwareDataset(\n    data_dir=COCO_DIR,\n    split=\"train\",\n    mode=\"instance\",\n    transform=transform,\n    max_samples=500\n)\n\nfrom torch.utils.data import DataLoader\ntrain_dataloader = DataLoader(\n    coco_dataset,\n    batch_size=1,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:35:40.484192Z","iopub.execute_input":"2025-07-19T04:35:40.484856Z","iopub.status.idle":"2025-07-19T04:36:04.429602Z","shell.execute_reply.started":"2025-07-19T04:35:40.484829Z","shell.execute_reply":"2025-07-19T04:36:04.428951Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=21.56s)\ncreating index...\nindex created!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# train fcn\nimport os\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\ndef to_str_list(x):\n    print(f\"[DEBUG] raw task_description type: {type(x)}, value: {x}\")\n    if isinstance(x, str):\n        return [x]\n    if isinstance(x, torch.Tensor):\n        if x.dtype == torch.object:\n            return [str(xx) for xx in x]\n        if x.numel() == 1:\n            return [str(x.item())]\n        else:\n            return [str(xx.item()) for xx in x]\n    if isinstance(x, bytes):\n        return [x.decode(\"utf8\")]\n    if isinstance(x, tuple):\n        return [str(xx) for xx in x]\n    if isinstance(x, list):\n        if all(isinstance(xx, list) for xx in x):\n            return [str(jj) for xx in x for jj in xx]\n        if all(isinstance(xx, torch.Tensor) for xx in x):\n            return [str(xx.item()) if xx.numel() == 1 else str(xx) for xx in x]\n        if all(isinstance(xx, bytes) for xx in x):\n            return [xx.decode(\"utf8\") for xx in x]\n        if all(isinstance(xx, str) for xx in x):\n            return x\n        return [str(xx) for xx in x]\n    return [str(x)]\n\noptimizer = torch.optim.AdamW(\n    hypernet.get_hypernetwork_params(),\n    lr=base_cfg.training.learning_rate,\n    weight_decay=base_cfg.training.weight_decay\n)\n\ndef train_epoch(hypernetwork, sam_model, dataloader, optimizer, epoch, device):\n    hypernetwork.train()\n    sam_model.train()\n    total_loss = 0\n\n    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}')\n    for batch_idx, batch in enumerate(pbar):\n        images = batch['image'].to(device)          \n        masks = batch['mask'].to(device)             \n        raw_task_desc = batch['task_description']\n\n        task_descriptions = to_str_list(raw_task_desc)\n        print(f\"[DEBUG] converted task_descriptions type: {type(task_descriptions)} value: {task_descriptions}\")\n\n        optimizer.zero_grad()\n\n        # get LoRA weights from hypernetwork\n        lora_weights = hypernetwork(task_descriptions)\n\n        # debug: print out each adapter’s provided shape\n        total_provided = 0\n        print(\"LoRA weights from hypernetwork:\")\n        for name, w in lora_weights.items():\n            print(f\"  • {name:40s} provided → {tuple(w.shape)}  (numel={w.numel()})\")\n            total_provided += w.numel()\n        print(f\"  → total provided params: {total_provided}\\n\")\n\n        #apply LoRA weights\n        sam_model.apply_lora(lora_weights)\n\n        #get and collect embeddings, squeezing out the extra dim\n        image_embeddings = []\n        for i in range(images.size(0)):\n            img_np = images[i].permute(1, 2, 0).cpu().numpy()\n            img_np = (img_np * 255).astype(np.uint8)\n            emb = sam_model.get_image_embeddings(img_np)    \n            emb = emb.squeeze(0)                            \n            image_embeddings.append(emb)\n        image_embeddings = torch.stack(image_embeddings).to(device)  \n\n        #prepare points\n        points = batch.get('points', None)\n        point_labels = batch.get('point_labels', None)\n        if points is None or point_labels is None:\n            b, c, h, w = images.shape\n            points = torch.tensor([[[w//2, h//2]]]*b).float().to(device)\n            point_labels = torch.ones((b,1), dtype=torch.long).to(device)\n        else:\n            points = points.to(device)\n            point_labels = point_labels.to(device)\n\n        #forward + loss\n        with torch.cuda.amp.autocast():\n            predicted_masks, _ = sam_model(\n                image_embeddings=image_embeddings,\n                point_coords=points,\n                point_labels=point_labels,\n                multimask_output=False\n            )  #predicted_masks: [B,1,256,256]\n\n            #resize ground-truth masks to match output\n            gt_masks = masks.unsqueeze(1).float()  \n            gt_masks = F.interpolate(\n                gt_masks,\n                size=predicted_masks.shape[-2:],   #(256,256)\n                mode='nearest'\n            ) \n\n            loss = F.binary_cross_entropy_with_logits(predicted_masks, gt_masks)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        pbar.set_postfix({'loss': loss.item()})\n\n        if batch_idx % 10 == 0:\n            torch.cuda.empty_cache()\n\n    return total_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:36:09.396112Z","iopub.execute_input":"2025-07-19T04:36:09.396393Z","iopub.status.idle":"2025-07-19T04:36:09.412335Z","shell.execute_reply.started":"2025-07-19T04:36:09.396373Z","shell.execute_reply":"2025-07-19T04:36:09.411338Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# train\nimport os\nimport torch\ndataloader = train_dataloader\n\nckpt_dir = \"/mnt/data/checkpoints\"\nos.makedirs(ckpt_dir, exist_ok=True)\n\ndef train_model(epochs, dataloader):\n    print(\"Starting training…\")\n    for epoch in range(epochs):\n        avg_loss = train_epoch(hypernet, sam_model, dataloader, optimizer, epoch, device)\n        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n        # save every epoch\n        checkpoint = {\n            'epoch': epoch,\n            'hypernetwork_state_dict': hypernet.state_dict(),\n            'sam_state_dict': sam_model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': avg_loss\n        }\n        path = f\"{ckpt_dir}/checkpoint_epoch_{epoch}.pth\"\n        torch.save(checkpoint, path)\n        print(f\" ✔️Saved checkpoint to {path}\")\n    print(\"Training completed!\")\n\ntrain_model(epochs=2, dataloader=train_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T05:06:17.966377Z","iopub.execute_input":"2025-07-19T05:06:17.967272Z","iopub.status.idle":"2025-07-19T05:44:25.578731Z","shell.execute_reply.started":"2025-07-19T05:06:17.967237Z","shell.execute_reply":"2025-07-19T05:44:25.577602Z"}},"outputs":[{"name":"stdout","text":"Starting training…\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   0%|          | 0/500 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"[DEBUG] raw task_description type: <class 'list'>, value: ['segment all baseball bat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all baseball bat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   0%|          | 1/500 [00:02<22:42,  2.73s/it, loss=0.15]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all frisbee']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all frisbee']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   0%|          | 2/500 [00:05<21:21,  2.57s/it, loss=0.12]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bird in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bird in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   1%|          | 3/500 [00:07<20:59,  2.53s/it, loss=1.98]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   1%|          | 4/500 [00:10<20:58,  2.54s/it, loss=1.49]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all white bird in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all white bird in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   1%|          | 5/500 [00:12<21:01,  2.55s/it, loss=0.0436]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   1%|          | 6/500 [00:15<21:03,  2.56s/it, loss=4.1]   ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all orange broccoli in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all orange broccoli in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   1%|▏         | 7/500 [00:17<20:59,  2.55s/it, loss=1.61]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   2%|▏         | 8/500 [00:20<20:50,  2.54s/it, loss=0.429]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   2%|▏         | 9/500 [00:22<20:32,  2.51s/it, loss=5.26] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   2%|▏         | 10/500 [00:25<20:14,  2.48s/it, loss=1.68]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   2%|▏         | 11/500 [00:27<19:59,  2.45s/it, loss=0.443]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   2%|▏         | 12/500 [00:30<19:42,  2.42s/it, loss=0.201]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all spoon']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all spoon']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   3%|▎         | 13/500 [00:32<19:22,  2.39s/it, loss=0.502]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   3%|▎         | 14/500 [00:34<19:07,  2.36s/it, loss=2.19] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all suitcase in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all suitcase in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   3%|▎         | 15/500 [00:36<18:51,  2.33s/it, loss=1.84]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment sink']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment sink']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   3%|▎         | 16/500 [00:39<18:36,  2.31s/it, loss=0.278]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all wide dog in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all wide dog in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   3%|▎         | 17/500 [00:41<18:22,  2.28s/it, loss=0.578]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   4%|▎         | 18/500 [00:43<18:10,  2.26s/it, loss=1.58] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment pink sink']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment pink sink']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   4%|▍         | 19/500 [00:45<18:03,  2.25s/it, loss=0.374]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   4%|▍         | 20/500 [00:48<17:55,  2.24s/it, loss=3.45] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all pink laptop objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all pink laptop objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   4%|▍         | 21/500 [00:50<17:50,  2.24s/it, loss=4.78]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   4%|▍         | 22/500 [00:52<17:46,  2.23s/it, loss=1.71]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   5%|▍         | 23/500 [00:54<17:37,  2.22s/it, loss=0.489]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all rectangular horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all rectangular horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   5%|▍         | 24/500 [00:56<17:31,  2.21s/it, loss=1.68] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   5%|▌         | 25/500 [00:59<17:26,  2.20s/it, loss=1.45]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all gray elephant from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all gray elephant from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   5%|▌         | 26/500 [01:01<17:22,  2.20s/it, loss=2.89]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment wide chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment wide chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   5%|▌         | 27/500 [01:03<17:21,  2.20s/it, loss=1.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bird in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bird in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   6%|▌         | 28/500 [01:05<17:17,  2.20s/it, loss=2.95]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   6%|▌         | 29/500 [01:07<17:18,  2.21s/it, loss=1.23]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   6%|▌         | 30/500 [01:10<17:19,  2.21s/it, loss=0.813]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment stop sign']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment stop sign']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   6%|▌         | 31/500 [01:12<17:22,  2.22s/it, loss=1.07] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   6%|▋         | 32/500 [01:14<17:22,  2.23s/it, loss=2.02]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all donut from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all donut from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   7%|▋         | 33/500 [01:16<17:22,  2.23s/it, loss=0.978]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   7%|▋         | 34/500 [01:19<17:21,  2.23s/it, loss=0.491]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   7%|▋         | 35/500 [01:21<17:20,  2.24s/it, loss=1.43] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all horse regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all horse regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   7%|▋         | 36/500 [01:23<17:21,  2.25s/it, loss=2.85]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment large person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment large person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   7%|▋         | 37/500 [01:25<17:23,  2.25s/it, loss=5.46]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   8%|▊         | 38/500 [01:28<17:26,  2.26s/it, loss=0.272]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   8%|▊         | 39/500 [01:30<17:26,  2.27s/it, loss=0.897]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all tall bench from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all tall bench from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   8%|▊         | 40/500 [01:32<17:27,  2.28s/it, loss=0.473]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment silver handbag']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment silver handbag']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   8%|▊         | 41/500 [01:35<17:33,  2.30s/it, loss=0.713]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all red backpack']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all red backpack']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   8%|▊         | 42/500 [01:37<17:35,  2.31s/it, loss=0.446]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   9%|▊         | 43/500 [01:39<17:34,  2.31s/it, loss=1.84] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment blue sink']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment blue sink']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   9%|▉         | 44/500 [01:41<17:32,  2.31s/it, loss=0.808]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every book']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every book']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   9%|▉         | 45/500 [01:44<17:28,  2.30s/it, loss=0.589]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all tall cat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all tall cat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   9%|▉         | 46/500 [01:46<17:26,  2.30s/it, loss=1.01] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all chair in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all chair in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   9%|▉         | 47/500 [01:48<17:24,  2.31s/it, loss=1.54]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  10%|▉         | 48/500 [01:51<17:21,  2.31s/it, loss=4.31]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all giraffe objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all giraffe objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  10%|▉         | 49/500 [01:53<17:19,  2.30s/it, loss=1.42]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment stop sign']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment stop sign']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  10%|█         | 50/500 [01:55<17:16,  2.30s/it, loss=3.62]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all silver cow regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all silver cow regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  10%|█         | 51/500 [01:58<17:16,  2.31s/it, loss=0.952]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  10%|█         | 52/500 [02:00<17:12,  2.30s/it, loss=0.265]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  11%|█         | 53/500 [02:02<17:07,  2.30s/it, loss=0.838]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment sheep']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment sheep']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  11%|█         | 54/500 [02:04<17:04,  2.30s/it, loss=3.63] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all zebra in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all zebra in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  11%|█         | 55/500 [02:07<17:00,  2.29s/it, loss=1.86]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all sink regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all sink regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  11%|█         | 56/500 [02:09<16:56,  2.29s/it, loss=2.35]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all purple person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all purple person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  11%|█▏        | 57/500 [02:11<16:53,  2.29s/it, loss=0.363]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every white person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every white person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  12%|█▏        | 58/500 [02:14<16:50,  2.29s/it, loss=1.45] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment fire hydrant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment fire hydrant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  12%|█▏        | 59/500 [02:16<16:46,  2.28s/it, loss=0.928]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all sports ball regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all sports ball regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  12%|█▏        | 60/500 [02:18<16:43,  2.28s/it, loss=0.402]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bowl']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bowl']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  12%|█▏        | 61/500 [02:20<16:41,  2.28s/it, loss=0.923]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all tie from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all tie from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  12%|█▏        | 62/500 [02:23<16:37,  2.28s/it, loss=0.744]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all gray toilet in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all gray toilet in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  13%|█▎        | 63/500 [02:25<16:32,  2.27s/it, loss=3.82] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all purple bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all purple bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  13%|█▎        | 64/500 [02:27<16:28,  2.27s/it, loss=1.35]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  13%|█▎        | 65/500 [02:30<16:26,  2.27s/it, loss=0.878]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment book']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment book']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  13%|█▎        | 66/500 [02:32<16:22,  2.26s/it, loss=0.348]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all motorcycle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all motorcycle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  13%|█▎        | 67/500 [02:34<16:17,  2.26s/it, loss=1.64] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  14%|█▎        | 68/500 [02:36<16:13,  2.25s/it, loss=1.83]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all mouse in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all mouse in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  14%|█▍        | 69/500 [02:39<16:11,  2.25s/it, loss=0.523]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every green giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every green giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  14%|█▍        | 70/500 [02:41<16:08,  2.25s/it, loss=1.09] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  14%|█▍        | 71/500 [02:43<16:07,  2.26s/it, loss=2.01]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all cat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all cat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  14%|█▍        | 72/500 [02:45<16:05,  2.26s/it, loss=0.681]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all elephant objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all elephant objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  15%|█▍        | 73/500 [02:48<16:01,  2.25s/it, loss=1.68] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  15%|█▍        | 74/500 [02:50<15:57,  2.25s/it, loss=0.238]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment vase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment vase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  15%|█▌        | 75/500 [02:52<15:55,  2.25s/it, loss=0.528]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every gray chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every gray chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  15%|█▌        | 76/500 [02:54<15:53,  2.25s/it, loss=5.51] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  15%|█▌        | 77/500 [02:57<15:50,  2.25s/it, loss=1.3] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bottle objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bottle objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  16%|█▌        | 78/500 [02:59<15:48,  2.25s/it, loss=1.86]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all tie regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all tie regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  16%|█▌        | 79/500 [03:01<15:49,  2.26s/it, loss=0.845]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every sink']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every sink']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  16%|█▌        | 80/500 [03:03<15:49,  2.26s/it, loss=1.38] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all white tv in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all white tv in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  16%|█▌        | 81/500 [03:06<15:52,  2.27s/it, loss=4.38]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all traffic light in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all traffic light in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  16%|█▋        | 82/500 [03:08<15:51,  2.28s/it, loss=0.472]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every black person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every black person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  17%|█▋        | 83/500 [03:10<15:49,  2.28s/it, loss=0.604]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all dog from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all dog from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  17%|█▋        | 84/500 [03:12<15:47,  2.28s/it, loss=0.385]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  17%|█▋        | 85/500 [03:15<15:44,  2.28s/it, loss=5.76] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  17%|█▋        | 86/500 [03:17<15:43,  2.28s/it, loss=0.717]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment long cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment long cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  17%|█▋        | 87/500 [03:19<15:43,  2.28s/it, loss=1.1]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  18%|█▊        | 88/500 [03:22<15:41,  2.28s/it, loss=0.875]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all sheep from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all sheep from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  18%|█▊        | 89/500 [03:24<15:39,  2.29s/it, loss=1.98] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all handbag']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all handbag']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  18%|█▊        | 90/500 [03:26<15:39,  2.29s/it, loss=0.308]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all train from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all train from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  18%|█▊        | 91/500 [03:28<15:40,  2.30s/it, loss=1.48] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  18%|█▊        | 92/500 [03:31<15:38,  2.30s/it, loss=0.287]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all tie from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all tie from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  19%|█▊        | 93/500 [03:33<15:35,  2.30s/it, loss=4.55] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  19%|█▉        | 94/500 [03:35<15:33,  2.30s/it, loss=4.02]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  19%|█▉        | 95/500 [03:38<15:30,  2.30s/it, loss=0.68]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  19%|█▉        | 96/500 [03:40<15:27,  2.30s/it, loss=4.72]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  19%|█▉        | 97/500 [03:42<15:25,  2.30s/it, loss=0.662]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all cat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all cat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  20%|█▉        | 98/500 [03:45<15:22,  2.29s/it, loss=2.22] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all zebra regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all zebra regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  20%|█▉        | 99/500 [03:47<15:20,  2.29s/it, loss=2.24]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every white truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every white truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  20%|██        | 100/500 [03:49<15:16,  2.29s/it, loss=2.66]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all boat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all boat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  20%|██        | 101/500 [03:51<15:14,  2.29s/it, loss=2.33]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all tall toilet regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all tall toilet regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  20%|██        | 102/500 [03:54<15:12,  2.29s/it, loss=0.384]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all round boat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all round boat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  21%|██        | 103/500 [03:56<15:08,  2.29s/it, loss=2.72] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every thin bottle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every thin bottle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  21%|██        | 104/500 [03:58<15:05,  2.29s/it, loss=0.318]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all laptop in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all laptop in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  21%|██        | 105/500 [04:01<15:00,  2.28s/it, loss=3.4]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all orange potted plant objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all orange potted plant objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  21%|██        | 106/500 [04:03<14:56,  2.27s/it, loss=4.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  21%|██▏       | 107/500 [04:05<14:52,  2.27s/it, loss=4.84]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  22%|██▏       | 108/500 [04:07<14:47,  2.26s/it, loss=5.26]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all black zebra regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all black zebra regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  22%|██▏       | 109/500 [04:10<14:44,  2.26s/it, loss=0.744]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every thin car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every thin car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  22%|██▏       | 110/500 [04:12<14:43,  2.27s/it, loss=1.72] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  22%|██▏       | 111/500 [04:14<14:44,  2.27s/it, loss=0.447]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bottle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bottle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  22%|██▏       | 112/500 [04:16<14:43,  2.28s/it, loss=0.623]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  23%|██▎       | 113/500 [04:19<14:38,  2.27s/it, loss=1.43] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all round car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all round car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  23%|██▎       | 114/500 [04:21<14:34,  2.27s/it, loss=3.59]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all dining table regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all dining table regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  23%|██▎       | 115/500 [04:23<14:32,  2.27s/it, loss=1.42]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all remote objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all remote objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  23%|██▎       | 116/500 [04:25<14:29,  2.27s/it, loss=1.16]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all blue couch regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all blue couch regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  23%|██▎       | 117/500 [04:28<14:27,  2.26s/it, loss=1.68]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  24%|██▎       | 118/500 [04:30<14:24,  2.26s/it, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  24%|██▍       | 119/500 [04:32<14:22,  2.26s/it, loss=2.9] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all dog in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all dog in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  24%|██▍       | 120/500 [04:35<14:19,  2.26s/it, loss=3.17]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all cake objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all cake objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  24%|██▍       | 121/500 [04:37<14:20,  2.27s/it, loss=3.29]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  24%|██▍       | 122/500 [04:39<14:17,  2.27s/it, loss=1.76]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all boat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all boat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  25%|██▍       | 123/500 [04:41<14:13,  2.26s/it, loss=3.2] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  25%|██▍       | 124/500 [04:44<14:09,  2.26s/it, loss=0.328]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment fire hydrant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment fire hydrant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  25%|██▌       | 125/500 [04:46<14:07,  2.26s/it, loss=0.154]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all large elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all large elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  25%|██▌       | 126/500 [04:48<14:04,  2.26s/it, loss=0.414]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all square sheep in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all square sheep in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  25%|██▌       | 127/500 [04:50<14:02,  2.26s/it, loss=0.668]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment silver horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment silver horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  26%|██▌       | 128/500 [04:53<13:59,  2.26s/it, loss=0.458]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment long cup']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment long cup']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  26%|██▌       | 129/500 [04:55<13:58,  2.26s/it, loss=0.228]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  26%|██▌       | 130/500 [04:57<13:56,  2.26s/it, loss=3.19] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all handbag from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all handbag from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  26%|██▌       | 131/500 [04:59<13:57,  2.27s/it, loss=0.198]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  26%|██▋       | 132/500 [05:02<13:54,  2.27s/it, loss=0.479]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bench']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bench']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  27%|██▋       | 133/500 [05:04<13:50,  2.26s/it, loss=0.56] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  27%|██▋       | 134/500 [05:06<13:47,  2.26s/it, loss=1.15]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all orange person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all orange person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  27%|██▋       | 135/500 [05:08<13:44,  2.26s/it, loss=0.915]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  27%|██▋       | 136/500 [05:11<13:40,  2.25s/it, loss=0.988]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment gray giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment gray giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  27%|██▋       | 137/500 [05:13<13:38,  2.26s/it, loss=1.37] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  28%|██▊       | 138/500 [05:15<13:37,  2.26s/it, loss=1.49]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all cup']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all cup']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  28%|██▊       | 139/500 [05:17<13:34,  2.26s/it, loss=0.591]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bowl regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bowl regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  28%|██▊       | 140/500 [05:20<13:31,  2.26s/it, loss=0.971]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  28%|██▊       | 141/500 [05:22<13:33,  2.27s/it, loss=0.94] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all cow in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all cow in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  28%|██▊       | 142/500 [05:24<13:28,  2.26s/it, loss=3.26]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all triangular person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all triangular person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  29%|██▊       | 143/500 [05:27<13:27,  2.26s/it, loss=3.01]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  29%|██▉       | 144/500 [05:29<13:25,  2.26s/it, loss=3.61]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment brown bottle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment brown bottle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  29%|██▉       | 145/500 [05:31<13:23,  2.26s/it, loss=0.221]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every silver bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every silver bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  29%|██▉       | 146/500 [05:33<13:21,  2.26s/it, loss=0.772]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bottle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bottle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  29%|██▉       | 147/500 [05:36<13:18,  2.26s/it, loss=0.169]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all sink regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all sink regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  30%|██▉       | 148/500 [05:38<13:16,  2.26s/it, loss=1.38] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment sink']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment sink']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  30%|██▉       | 149/500 [05:40<13:13,  2.26s/it, loss=1.26]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all horse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all horse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  30%|███       | 150/500 [05:42<13:12,  2.26s/it, loss=2.54]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  30%|███       | 151/500 [05:45<13:13,  2.27s/it, loss=0.258]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment wide person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment wide person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  30%|███       | 152/500 [05:47<13:11,  2.27s/it, loss=0.229]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all brown truck from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all brown truck from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  31%|███       | 153/500 [05:49<13:09,  2.27s/it, loss=0.136]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bottle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bottle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  31%|███       | 154/500 [05:51<13:06,  2.27s/it, loss=0.231]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all long bus regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all long bus regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  31%|███       | 155/500 [05:54<13:03,  2.27s/it, loss=0.279]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all dog objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all dog objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  31%|███       | 156/500 [05:56<13:00,  2.27s/it, loss=0.149]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  31%|███▏      | 157/500 [05:58<12:59,  2.27s/it, loss=2.65] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  32%|███▏      | 158/500 [06:01<12:57,  2.27s/it, loss=1.49]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all elephant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all elephant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  32%|███▏      | 159/500 [06:03<12:56,  2.28s/it, loss=1.53]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment black elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment black elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  32%|███▏      | 160/500 [06:05<12:54,  2.28s/it, loss=2.22]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bird objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bird objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  32%|███▏      | 161/500 [06:07<12:54,  2.28s/it, loss=2.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  32%|███▏      | 162/500 [06:10<12:52,  2.29s/it, loss=2.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all elephant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all elephant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  33%|███▎      | 163/500 [06:12<12:50,  2.29s/it, loss=2.57]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  33%|███▎      | 164/500 [06:14<12:47,  2.28s/it, loss=0.986]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  33%|███▎      | 165/500 [06:17<12:44,  2.28s/it, loss=5.22] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment microwave']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment microwave']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  33%|███▎      | 166/500 [06:19<12:41,  2.28s/it, loss=1.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment brown elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment brown elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  33%|███▎      | 167/500 [06:21<12:38,  2.28s/it, loss=0.804]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all car from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all car from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  34%|███▎      | 168/500 [06:23<12:36,  2.28s/it, loss=2]    ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment gray bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment gray bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  34%|███▍      | 169/500 [06:26<12:33,  2.28s/it, loss=2.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment small bench']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment small bench']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  34%|███▍      | 170/500 [06:28<12:31,  2.28s/it, loss=0.544]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all sheep objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all sheep objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  34%|███▍      | 171/500 [06:30<12:32,  2.29s/it, loss=0.225]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all sheep in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all sheep in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  34%|███▍      | 172/500 [06:33<12:30,  2.29s/it, loss=0.113]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all boat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all boat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  35%|███▍      | 173/500 [06:35<12:28,  2.29s/it, loss=4.56] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  35%|███▍      | 174/500 [06:37<12:27,  2.29s/it, loss=0.885]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  35%|███▌      | 175/500 [06:39<12:23,  2.29s/it, loss=4.68] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  35%|███▌      | 176/500 [06:42<12:21,  2.29s/it, loss=2.91]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  35%|███▌      | 177/500 [06:44<12:18,  2.29s/it, loss=2.79]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all orange from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all orange from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  36%|███▌      | 178/500 [06:46<12:16,  2.29s/it, loss=1.37]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all banana objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all banana objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  36%|███▌      | 179/500 [06:49<12:14,  2.29s/it, loss=1.93]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all tall tv in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all tall tv in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  36%|███▌      | 180/500 [06:51<12:11,  2.29s/it, loss=1.96]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all elephant objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all elephant objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  36%|███▌      | 181/500 [06:53<12:11,  2.29s/it, loss=2.04]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  36%|███▋      | 182/500 [06:55<12:09,  2.29s/it, loss=0.696]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment vase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment vase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  37%|███▋      | 183/500 [06:58<12:06,  2.29s/it, loss=0.628]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bear in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bear in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  37%|███▋      | 184/500 [07:00<12:03,  2.29s/it, loss=1.69] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment tall stop sign']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment tall stop sign']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  37%|███▋      | 185/500 [07:02<11:59,  2.29s/it, loss=0.447]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bowl']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bowl']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  37%|███▋      | 186/500 [07:05<11:57,  2.29s/it, loss=0.169]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  37%|███▋      | 187/500 [07:07<11:55,  2.29s/it, loss=2.09] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  38%|███▊      | 188/500 [07:09<11:52,  2.29s/it, loss=0.853]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  38%|███▊      | 189/500 [07:11<11:51,  2.29s/it, loss=1.63] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all red tie']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all red tie']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  38%|███▊      | 190/500 [07:14<11:49,  2.29s/it, loss=8.72]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment triangular person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment triangular person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  38%|███▊      | 191/500 [07:16<11:49,  2.29s/it, loss=0.789]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all tall motorcycle objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all tall motorcycle objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  38%|███▊      | 192/500 [07:18<11:45,  2.29s/it, loss=2.61] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  39%|███▊      | 193/500 [07:21<11:42,  2.29s/it, loss=0.706]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  39%|███▉      | 194/500 [07:23<11:38,  2.28s/it, loss=0.395]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all sink from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all sink from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  39%|███▉      | 195/500 [07:25<11:36,  2.28s/it, loss=0.922]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  39%|███▉      | 196/500 [07:27<11:32,  2.28s/it, loss=1.85] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every tall bottle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every tall bottle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  39%|███▉      | 197/500 [07:30<11:28,  2.27s/it, loss=0.43]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment parking meter']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment parking meter']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  40%|███▉      | 198/500 [07:32<11:26,  2.27s/it, loss=1.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment dining table']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment dining table']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  40%|███▉      | 199/500 [07:34<11:23,  2.27s/it, loss=2.41]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all wine glass regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all wine glass regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  40%|████      | 200/500 [07:37<11:22,  2.27s/it, loss=0.46]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all suitcase regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all suitcase regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  40%|████      | 201/500 [07:39<11:21,  2.28s/it, loss=1.32]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all sink from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all sink from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  40%|████      | 202/500 [07:41<11:19,  2.28s/it, loss=0.915]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  41%|████      | 203/500 [07:43<11:16,  2.28s/it, loss=1.45] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  41%|████      | 204/500 [07:46<11:12,  2.27s/it, loss=3.81]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment blue person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment blue person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  41%|████      | 205/500 [07:48<11:09,  2.27s/it, loss=0.171]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  41%|████      | 206/500 [07:50<11:06,  2.27s/it, loss=2.76] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all suitcase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all suitcase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  41%|████▏     | 207/500 [07:52<11:04,  2.27s/it, loss=2.76]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all oval sheep in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all oval sheep in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  42%|████▏     | 208/500 [07:55<11:02,  2.27s/it, loss=1.48]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment black person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment black person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  42%|████▏     | 209/500 [07:57<11:00,  2.27s/it, loss=2.33]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all large clock objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all large clock objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  42%|████▏     | 210/500 [07:59<10:58,  2.27s/it, loss=1.09]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  42%|████▏     | 211/500 [08:02<10:57,  2.28s/it, loss=1.1] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all blue toilet objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all blue toilet objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  42%|████▏     | 212/500 [08:04<10:56,  2.28s/it, loss=0.38]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  43%|████▎     | 213/500 [08:06<10:53,  2.28s/it, loss=1]   ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every thin zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every thin zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  43%|████▎     | 214/500 [08:08<10:50,  2.27s/it, loss=0.453]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all long person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all long person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  43%|████▎     | 215/500 [08:11<10:48,  2.28s/it, loss=2.14] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  43%|████▎     | 216/500 [08:13<10:45,  2.27s/it, loss=3.95]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all backpack in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all backpack in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  43%|████▎     | 217/500 [08:15<10:43,  2.27s/it, loss=0.994]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  44%|████▎     | 218/500 [08:17<10:40,  2.27s/it, loss=2.21] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all stop sign in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all stop sign in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  44%|████▍     | 219/500 [08:20<10:38,  2.27s/it, loss=0.729]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bicycle objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bicycle objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  44%|████▍     | 220/500 [08:22<10:36,  2.27s/it, loss=1.59] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all pink sheep regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all pink sheep regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  44%|████▍     | 221/500 [08:24<10:35,  2.28s/it, loss=1.24]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all handbag from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all handbag from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  44%|████▍     | 222/500 [08:27<10:34,  2.28s/it, loss=0.631]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bus']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bus']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  45%|████▍     | 223/500 [08:29<10:32,  2.28s/it, loss=5.12] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  45%|████▍     | 224/500 [08:31<10:29,  2.28s/it, loss=0.349]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment parking meter']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment parking meter']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  45%|████▌     | 225/500 [08:33<10:27,  2.28s/it, loss=0.954]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all round chair regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all round chair regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  45%|████▌     | 226/500 [08:36<10:24,  2.28s/it, loss=0.134]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all fire hydrant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all fire hydrant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  45%|████▌     | 227/500 [08:38<10:22,  2.28s/it, loss=1.25] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all truck from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all truck from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  46%|████▌     | 228/500 [08:40<10:20,  2.28s/it, loss=0.694]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bottle in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bottle in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  46%|████▌     | 229/500 [08:43<10:18,  2.28s/it, loss=0.271]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  46%|████▌     | 230/500 [08:45<10:15,  2.28s/it, loss=0.6]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all thin zebra objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all thin zebra objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  46%|████▌     | 231/500 [08:47<10:15,  2.29s/it, loss=2.41]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all rectangular airplane objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all rectangular airplane objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  46%|████▋     | 232/500 [08:49<10:14,  2.29s/it, loss=2.44]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  47%|████▋     | 233/500 [08:52<10:10,  2.29s/it, loss=2.98]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  47%|████▋     | 234/500 [08:54<10:07,  2.29s/it, loss=0.134]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all refrigerator regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all refrigerator regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  47%|████▋     | 235/500 [08:56<10:05,  2.28s/it, loss=0.768]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment silver horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment silver horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  47%|████▋     | 236/500 [08:59<10:03,  2.29s/it, loss=1.19] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  47%|████▋     | 237/500 [09:01<10:00,  2.29s/it, loss=0.0714]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment blue keyboard']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment blue keyboard']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  48%|████▊     | 238/500 [09:03<09:57,  2.28s/it, loss=5.03]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  48%|████▊     | 239/500 [09:05<09:54,  2.28s/it, loss=0.238]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  48%|████▊     | 240/500 [09:08<09:52,  2.28s/it, loss=4.46] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  48%|████▊     | 241/500 [09:10<09:52,  2.29s/it, loss=2.59]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all small bus']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all small bus']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  48%|████▊     | 242/500 [09:12<09:50,  2.29s/it, loss=1.12]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment couch']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment couch']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  49%|████▊     | 243/500 [09:15<09:47,  2.29s/it, loss=1.69]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  49%|████▉     | 244/500 [09:17<09:45,  2.29s/it, loss=3.49]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  49%|████▉     | 245/500 [09:19<09:42,  2.29s/it, loss=1.34]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all handbag']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all handbag']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  49%|████▉     | 246/500 [09:21<09:40,  2.29s/it, loss=0.354]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every fire hydrant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every fire hydrant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  49%|████▉     | 247/500 [09:24<09:38,  2.29s/it, loss=2.34] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  50%|████▉     | 248/500 [09:26<09:35,  2.28s/it, loss=3.84]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  50%|████▉     | 249/500 [09:28<09:33,  2.29s/it, loss=3.9] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every wide bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every wide bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  50%|█████     | 250/500 [09:31<09:31,  2.29s/it, loss=0.844]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every circular umbrella']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every circular umbrella']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  50%|█████     | 251/500 [09:33<09:31,  2.29s/it, loss=0.342]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all umbrella from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all umbrella from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  50%|█████     | 252/500 [09:35<09:28,  2.29s/it, loss=2.4]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  51%|█████     | 253/500 [09:37<09:25,  2.29s/it, loss=1.04]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment stop sign']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment stop sign']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  51%|█████     | 254/500 [09:40<09:23,  2.29s/it, loss=2.83]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  51%|█████     | 255/500 [09:42<09:21,  2.29s/it, loss=2.11]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all giraffe objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all giraffe objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  51%|█████     | 256/500 [09:44<09:18,  2.29s/it, loss=1.65]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every white bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every white bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  51%|█████▏    | 257/500 [09:47<09:15,  2.29s/it, loss=2.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  52%|█████▏    | 258/500 [09:49<09:14,  2.29s/it, loss=0.195]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  52%|█████▏    | 259/500 [09:51<09:11,  2.29s/it, loss=0.815]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all sink']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all sink']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  52%|█████▏    | 260/500 [09:53<09:09,  2.29s/it, loss=0.688]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment motorcycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment motorcycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  52%|█████▏    | 261/500 [09:56<09:09,  2.30s/it, loss=2.03] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all square bench from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all square bench from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  52%|█████▏    | 262/500 [09:58<09:06,  2.30s/it, loss=0.919]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all gray cow objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all gray cow objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  53%|█████▎    | 263/500 [10:00<09:03,  2.29s/it, loss=0.921]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment round person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment round person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  53%|█████▎    | 264/500 [10:03<09:00,  2.29s/it, loss=4.53] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  53%|█████▎    | 265/500 [10:05<08:57,  2.29s/it, loss=1.5] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all purple bowl']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all purple bowl']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  53%|█████▎    | 266/500 [10:07<08:54,  2.28s/it, loss=0.233]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all boat objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all boat objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  53%|█████▎    | 267/500 [10:09<08:51,  2.28s/it, loss=2.64] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all vase in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all vase in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  54%|█████▎    | 268/500 [10:12<08:49,  2.28s/it, loss=0.116]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment remote']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment remote']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  54%|█████▍    | 269/500 [10:14<08:47,  2.29s/it, loss=0.7]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  54%|█████▍    | 270/500 [10:16<08:45,  2.28s/it, loss=0.292]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment tv']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment tv']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  54%|█████▍    | 271/500 [10:19<08:43,  2.29s/it, loss=2.65] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bench regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bench regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  54%|█████▍    | 272/500 [10:21<08:41,  2.29s/it, loss=0.247]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all white person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all white person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  55%|█████▍    | 273/500 [10:23<08:38,  2.28s/it, loss=4.11] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  55%|█████▍    | 274/500 [10:25<08:35,  2.28s/it, loss=1.72]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all orange clock from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all orange clock from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  55%|█████▌    | 275/500 [10:28<08:32,  2.28s/it, loss=3.65]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all dining table from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all dining table from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  55%|█████▌    | 276/500 [10:30<08:29,  2.27s/it, loss=1.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  55%|█████▌    | 277/500 [10:32<08:26,  2.27s/it, loss=1.03]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  56%|█████▌    | 278/500 [10:35<08:24,  2.27s/it, loss=1.74]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment gray cup']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment gray cup']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  56%|█████▌    | 279/500 [10:37<08:22,  2.27s/it, loss=0.312]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all triangular zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all triangular zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  56%|█████▌    | 280/500 [10:39<08:20,  2.27s/it, loss=2.45] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment black airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment black airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  56%|█████▌    | 281/500 [10:41<08:18,  2.28s/it, loss=3.77]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  56%|█████▋    | 282/500 [10:44<08:16,  2.28s/it, loss=1.94]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  57%|█████▋    | 283/500 [10:46<08:13,  2.27s/it, loss=2.29]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all truck objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all truck objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  57%|█████▋    | 284/500 [10:48<08:11,  2.27s/it, loss=0.82]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every frisbee']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every frisbee']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  57%|█████▋    | 285/500 [10:50<08:08,  2.27s/it, loss=0.746]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  57%|█████▋    | 286/500 [10:53<08:05,  2.27s/it, loss=0.582]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  57%|█████▋    | 287/500 [10:55<08:03,  2.27s/it, loss=4.14] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all round cat objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all round cat objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  58%|█████▊    | 288/500 [10:57<08:01,  2.27s/it, loss=0.606]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every tall cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every tall cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  58%|█████▊    | 289/500 [11:00<07:59,  2.27s/it, loss=3.24] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment tv']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment tv']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  58%|█████▊    | 290/500 [11:02<07:56,  2.27s/it, loss=1.43]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  58%|█████▊    | 291/500 [11:04<07:55,  2.28s/it, loss=2.46]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  58%|█████▊    | 292/500 [11:06<07:53,  2.28s/it, loss=2.94]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  59%|█████▊    | 293/500 [11:09<07:51,  2.28s/it, loss=0.89]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all zebra regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all zebra regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  59%|█████▉    | 294/500 [11:11<07:48,  2.27s/it, loss=2.23]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  59%|█████▉    | 295/500 [11:13<07:45,  2.27s/it, loss=0.725]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all giraffe regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all giraffe regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  59%|█████▉    | 296/500 [11:15<07:43,  2.27s/it, loss=2.22] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  59%|█████▉    | 297/500 [11:18<07:41,  2.27s/it, loss=1.31]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all thin boat regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all thin boat regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  60%|█████▉    | 298/500 [11:20<07:38,  2.27s/it, loss=1.03]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all keyboard regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all keyboard regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  60%|█████▉    | 299/500 [11:22<07:36,  2.27s/it, loss=0.684]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  60%|██████    | 300/500 [11:25<07:34,  2.27s/it, loss=2.9]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all gray book objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all gray book objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  60%|██████    | 301/500 [11:27<07:34,  2.28s/it, loss=0.533]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all tie in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all tie in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  60%|██████    | 302/500 [11:29<07:32,  2.28s/it, loss=0.752]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all large sink objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all large sink objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  61%|██████    | 303/500 [11:31<07:29,  2.28s/it, loss=1.47] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all cat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all cat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  61%|██████    | 304/500 [11:34<07:27,  2.28s/it, loss=0.101]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  61%|██████    | 305/500 [11:36<07:24,  2.28s/it, loss=2.56] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all horse in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all horse in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  61%|██████    | 306/500 [11:38<07:22,  2.28s/it, loss=3.03]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  61%|██████▏   | 307/500 [11:41<07:19,  2.28s/it, loss=1.53]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment vase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment vase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  62%|██████▏   | 308/500 [11:43<07:17,  2.28s/it, loss=0.388]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all small refrigerator']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all small refrigerator']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  62%|██████▏   | 309/500 [11:45<07:15,  2.28s/it, loss=1.47] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  62%|██████▏   | 310/500 [11:47<07:13,  2.28s/it, loss=1.37]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  62%|██████▏   | 311/500 [11:50<07:11,  2.28s/it, loss=3.81]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  62%|██████▏   | 312/500 [11:52<07:09,  2.28s/it, loss=0.46]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  63%|██████▎   | 313/500 [11:54<07:07,  2.28s/it, loss=2.71]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  63%|██████▎   | 314/500 [11:57<07:04,  2.28s/it, loss=0.394]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all blue sheep']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all blue sheep']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  63%|██████▎   | 315/500 [11:59<07:02,  2.29s/it, loss=1.21] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all zebra in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all zebra in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  63%|██████▎   | 316/500 [12:01<06:59,  2.28s/it, loss=1.55]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  63%|██████▎   | 317/500 [12:03<06:58,  2.28s/it, loss=0.17]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all black giraffe from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all black giraffe from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  64%|██████▎   | 318/500 [12:06<06:55,  2.28s/it, loss=1.57]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all motorcycle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all motorcycle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  64%|██████▍   | 319/500 [12:08<06:52,  2.28s/it, loss=0.447]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  64%|██████▍   | 320/500 [12:10<06:50,  2.28s/it, loss=0.682]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  64%|██████▍   | 321/500 [12:12<06:49,  2.29s/it, loss=2.37] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every book']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every book']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  64%|██████▍   | 322/500 [12:15<06:46,  2.29s/it, loss=0.601]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bird objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bird objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  65%|██████▍   | 323/500 [12:17<06:43,  2.28s/it, loss=1.7]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all round dog from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all round dog from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  65%|██████▍   | 324/500 [12:19<06:41,  2.28s/it, loss=2.02]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment banana']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment banana']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  65%|██████▌   | 325/500 [12:22<06:38,  2.28s/it, loss=4.06]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all motorcycle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all motorcycle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  65%|██████▌   | 326/500 [12:24<06:36,  2.28s/it, loss=1.63]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all zebra regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all zebra regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  65%|██████▌   | 327/500 [12:26<06:33,  2.27s/it, loss=1.24]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all traffic light from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all traffic light from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  66%|██████▌   | 328/500 [12:28<06:30,  2.27s/it, loss=0.705]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bird objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bird objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  66%|██████▌   | 329/500 [12:31<06:27,  2.27s/it, loss=3.57] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  66%|██████▌   | 330/500 [12:33<06:24,  2.26s/it, loss=2.2] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all backpack in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all backpack in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  66%|██████▌   | 331/500 [12:35<06:23,  2.27s/it, loss=0.206]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all zebra from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all zebra from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  66%|██████▋   | 332/500 [12:37<06:20,  2.27s/it, loss=0.962]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all long person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all long person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  67%|██████▋   | 333/500 [12:40<06:18,  2.26s/it, loss=0.351]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all rectangular toilet from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all rectangular toilet from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  67%|██████▋   | 334/500 [12:42<06:15,  2.26s/it, loss=1.44] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  67%|██████▋   | 335/500 [12:44<06:13,  2.26s/it, loss=0.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  67%|██████▋   | 336/500 [12:47<06:11,  2.27s/it, loss=0.899]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  67%|██████▋   | 337/500 [12:49<06:08,  2.26s/it, loss=5.91] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all thin zebra objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all thin zebra objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  68%|██████▊   | 338/500 [12:51<06:06,  2.27s/it, loss=5.97]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  68%|██████▊   | 339/500 [12:53<06:05,  2.27s/it, loss=0.48]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all long elephant objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all long elephant objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  68%|██████▊   | 340/500 [12:56<06:02,  2.27s/it, loss=4.67]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment brown person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment brown person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  68%|██████▊   | 341/500 [12:58<06:01,  2.27s/it, loss=0.25]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment brown dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment brown dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  68%|██████▊   | 342/500 [13:00<05:59,  2.28s/it, loss=2.52]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  69%|██████▊   | 343/500 [13:02<05:57,  2.28s/it, loss=0.599]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all book']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all book']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  69%|██████▉   | 344/500 [13:05<05:54,  2.27s/it, loss=2.11] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all toilet from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all toilet from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  69%|██████▉   | 345/500 [13:07<05:51,  2.27s/it, loss=0.149]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all long person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all long person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  69%|██████▉   | 346/500 [13:09<05:49,  2.27s/it, loss=5]    ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  69%|██████▉   | 347/500 [13:11<05:46,  2.27s/it, loss=0.513]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all traffic light objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all traffic light objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  70%|██████▉   | 348/500 [13:14<05:44,  2.27s/it, loss=2.83] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment circular horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment circular horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  70%|██████▉   | 349/500 [13:16<05:42,  2.27s/it, loss=4.31]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  70%|███████   | 350/500 [13:18<05:40,  2.27s/it, loss=0.481]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all gray traffic light from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all gray traffic light from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  70%|███████   | 351/500 [13:21<05:39,  2.28s/it, loss=3.81] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all elephant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all elephant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  70%|███████   | 352/500 [13:23<05:36,  2.27s/it, loss=2.24]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all pink bicycle regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all pink bicycle regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  71%|███████   | 353/500 [13:25<05:34,  2.28s/it, loss=0.875]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  71%|███████   | 354/500 [13:27<05:31,  2.27s/it, loss=2.15] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all cat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all cat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  71%|███████   | 355/500 [13:30<05:28,  2.27s/it, loss=1.27]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  71%|███████   | 356/500 [13:32<05:26,  2.27s/it, loss=1.3] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every silver zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every silver zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  71%|███████▏  | 357/500 [13:34<05:24,  2.27s/it, loss=2.65]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  72%|███████▏  | 358/500 [13:36<05:22,  2.27s/it, loss=0.905]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  72%|███████▏  | 359/500 [13:39<05:19,  2.27s/it, loss=0.175]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  72%|███████▏  | 360/500 [13:41<05:17,  2.27s/it, loss=1.2]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  72%|███████▏  | 361/500 [13:43<05:16,  2.28s/it, loss=0.147]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all giraffe from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all giraffe from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  72%|███████▏  | 362/500 [13:46<05:14,  2.28s/it, loss=4.99] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all long chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all long chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  73%|███████▎  | 363/500 [13:48<05:11,  2.27s/it, loss=0.807]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all elephant objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all elephant objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  73%|███████▎  | 364/500 [13:50<05:08,  2.27s/it, loss=2.97] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  73%|███████▎  | 365/500 [13:52<05:06,  2.27s/it, loss=0.33]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  73%|███████▎  | 366/500 [13:55<05:04,  2.27s/it, loss=0.196]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all horse in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all horse in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  73%|███████▎  | 367/500 [13:57<05:01,  2.27s/it, loss=3.19] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  74%|███████▎  | 368/500 [13:59<04:59,  2.27s/it, loss=1.7] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all blue potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all blue potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  74%|███████▍  | 369/500 [14:01<04:56,  2.27s/it, loss=1.08]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment book']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment book']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  74%|███████▍  | 370/500 [14:04<04:54,  2.27s/it, loss=1.3] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  74%|███████▍  | 371/500 [14:06<04:53,  2.27s/it, loss=1.87]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all traffic light from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all traffic light from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  74%|███████▍  | 372/500 [14:08<04:51,  2.28s/it, loss=0.951]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every orange car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every orange car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  75%|███████▍  | 373/500 [14:11<04:48,  2.27s/it, loss=0.228]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all boat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all boat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  75%|███████▍  | 374/500 [14:13<04:46,  2.27s/it, loss=0.612]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  75%|███████▌  | 375/500 [14:15<04:44,  2.27s/it, loss=0.398]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  75%|███████▌  | 376/500 [14:17<04:41,  2.27s/it, loss=2.75] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all white zebra from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all white zebra from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  75%|███████▌  | 377/500 [14:20<04:39,  2.27s/it, loss=2.34]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  76%|███████▌  | 378/500 [14:22<04:37,  2.27s/it, loss=0.589]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all sink objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all sink objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  76%|███████▌  | 379/500 [14:24<04:35,  2.27s/it, loss=0.948]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every wide banana']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every wide banana']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  76%|███████▌  | 380/500 [14:26<04:32,  2.27s/it, loss=1.32] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  76%|███████▌  | 381/500 [14:29<04:31,  2.28s/it, loss=1.08]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all purple horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all purple horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  76%|███████▋  | 382/500 [14:31<04:28,  2.28s/it, loss=3.6] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all triangular toilet objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all triangular toilet objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  77%|███████▋  | 383/500 [14:33<04:26,  2.28s/it, loss=0.6]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all cow from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all cow from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  77%|███████▋  | 384/500 [14:36<04:23,  2.27s/it, loss=2.33]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  77%|███████▋  | 385/500 [14:38<04:21,  2.28s/it, loss=0.961]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all gray cow in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all gray cow in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  77%|███████▋  | 386/500 [14:40<04:19,  2.28s/it, loss=3.38] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all toothbrush regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all toothbrush regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  77%|███████▋  | 387/500 [14:42<04:17,  2.28s/it, loss=0.117]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  78%|███████▊  | 388/500 [14:45<04:15,  2.28s/it, loss=1.36] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all white horse regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all white horse regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  78%|███████▊  | 389/500 [14:47<04:12,  2.28s/it, loss=6.01]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all cow in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all cow in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  78%|███████▊  | 390/500 [14:49<04:10,  2.28s/it, loss=3.03]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all blue toilet objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all blue toilet objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  78%|███████▊  | 391/500 [14:52<04:09,  2.29s/it, loss=1.96]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment bottle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment bottle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  78%|███████▊  | 392/500 [14:54<04:07,  2.29s/it, loss=0.186]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every suitcase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every suitcase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  79%|███████▊  | 393/500 [14:56<04:05,  2.29s/it, loss=1.78] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  79%|███████▉  | 394/500 [14:58<04:02,  2.29s/it, loss=0.291]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  79%|███████▉  | 395/500 [15:01<04:00,  2.29s/it, loss=3.22] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all sheep']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all sheep']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  79%|███████▉  | 396/500 [15:03<03:57,  2.29s/it, loss=1.18]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all suitcase regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all suitcase regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  79%|███████▉  | 397/500 [15:05<03:55,  2.28s/it, loss=1.88]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment square cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment square cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  80%|███████▉  | 398/500 [15:08<03:52,  2.28s/it, loss=1.74]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  80%|███████▉  | 399/500 [15:10<03:50,  2.28s/it, loss=0.692]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  80%|████████  | 400/500 [15:12<03:48,  2.28s/it, loss=8.93] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all red airplane regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all red airplane regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  80%|████████  | 401/500 [15:14<03:46,  2.29s/it, loss=3.26]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every brown train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every brown train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  80%|████████  | 402/500 [15:17<03:44,  2.29s/it, loss=4.42]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  81%|████████  | 403/500 [15:19<03:41,  2.29s/it, loss=3.69]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all airplane from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all airplane from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  81%|████████  | 404/500 [15:21<03:39,  2.28s/it, loss=2.62]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bus']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bus']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  81%|████████  | 405/500 [15:24<03:37,  2.29s/it, loss=0.351]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  81%|████████  | 406/500 [15:26<03:34,  2.29s/it, loss=6.1]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  81%|████████▏ | 407/500 [15:28<03:32,  2.29s/it, loss=1.28]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  82%|████████▏ | 408/500 [15:30<03:30,  2.29s/it, loss=3.11]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all book objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all book objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  82%|████████▏ | 409/500 [15:33<03:28,  2.29s/it, loss=0.593]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all silver bench']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all silver bench']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  82%|████████▏ | 410/500 [15:35<03:26,  2.29s/it, loss=1.02] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every umbrella']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every umbrella']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  82%|████████▏ | 411/500 [15:37<03:24,  2.30s/it, loss=0.201]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  82%|████████▏ | 412/500 [15:40<03:22,  2.30s/it, loss=0.737]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  83%|████████▎ | 413/500 [15:42<03:19,  2.30s/it, loss=2.96] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  83%|████████▎ | 414/500 [15:44<03:17,  2.29s/it, loss=2.48]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all cat regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all cat regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  83%|████████▎ | 415/500 [15:46<03:14,  2.29s/it, loss=1.46]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all cow objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all cow objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  83%|████████▎ | 416/500 [15:49<03:11,  2.28s/it, loss=1.89]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  83%|████████▎ | 417/500 [15:51<03:09,  2.28s/it, loss=2.75]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  84%|████████▎ | 418/500 [15:53<03:06,  2.28s/it, loss=0.411]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all traffic light objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all traffic light objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  84%|████████▍ | 419/500 [15:56<03:04,  2.28s/it, loss=2.02] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment round dining table']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment round dining table']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  84%|████████▍ | 420/500 [15:58<03:02,  2.28s/it, loss=1.71]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all long umbrella']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all long umbrella']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  84%|████████▍ | 421/500 [16:00<03:00,  2.29s/it, loss=1.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  84%|████████▍ | 422/500 [16:02<02:58,  2.29s/it, loss=3.87]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all round truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all round truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  85%|████████▍ | 423/500 [16:05<02:56,  2.29s/it, loss=0.684]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all circular person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all circular person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  85%|████████▍ | 424/500 [16:07<02:53,  2.29s/it, loss=1.7]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  85%|████████▌ | 425/500 [16:09<02:51,  2.29s/it, loss=5.31]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all surfboard objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all surfboard objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  85%|████████▌ | 426/500 [16:12<02:49,  2.29s/it, loss=0.555]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all horse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all horse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  85%|████████▌ | 427/500 [16:14<02:46,  2.28s/it, loss=2.25] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all horse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all horse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  86%|████████▌ | 428/500 [16:16<02:44,  2.28s/it, loss=2.92]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all sink regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all sink regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  86%|████████▌ | 429/500 [16:18<02:41,  2.28s/it, loss=1.96]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  86%|████████▌ | 430/500 [16:21<02:39,  2.28s/it, loss=0.504]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bicycle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bicycle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  86%|████████▌ | 431/500 [16:23<02:37,  2.29s/it, loss=1.14] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all potted plant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all potted plant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  86%|████████▋ | 432/500 [16:25<02:35,  2.29s/it, loss=2.58]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all motorcycle regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all motorcycle regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  87%|████████▋ | 433/500 [16:28<02:32,  2.28s/it, loss=2.88]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  87%|████████▋ | 434/500 [16:30<02:30,  2.28s/it, loss=1.32]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bottle in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bottle in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  87%|████████▋ | 435/500 [16:32<02:28,  2.28s/it, loss=3.9] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  87%|████████▋ | 436/500 [16:34<02:25,  2.28s/it, loss=2.97]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all teddy bear regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all teddy bear regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  87%|████████▋ | 437/500 [16:37<02:23,  2.28s/it, loss=0.174]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment round bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment round bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  88%|████████▊ | 438/500 [16:39<02:21,  2.28s/it, loss=1.28] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all traffic light in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all traffic light in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  88%|████████▊ | 439/500 [16:41<02:18,  2.28s/it, loss=0.185]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every wide car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every wide car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  88%|████████▊ | 440/500 [16:43<02:16,  2.28s/it, loss=0.217]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all yellow person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all yellow person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  88%|████████▊ | 441/500 [16:46<02:14,  2.28s/it, loss=0.288]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  88%|████████▊ | 442/500 [16:48<02:12,  2.28s/it, loss=1.25] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all bicycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all bicycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  89%|████████▊ | 443/500 [16:50<02:10,  2.28s/it, loss=0.449]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all frisbee objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all frisbee objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  89%|████████▉ | 444/500 [16:53<02:07,  2.28s/it, loss=1.57] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bed from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bed from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  89%|████████▉ | 445/500 [16:55<02:05,  2.28s/it, loss=3.26]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  89%|████████▉ | 446/500 [16:57<02:03,  2.28s/it, loss=1.91]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  89%|████████▉ | 447/500 [16:59<02:00,  2.28s/it, loss=0.627]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment fire hydrant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment fire hydrant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  90%|████████▉ | 448/500 [17:02<01:58,  2.28s/it, loss=1.45] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  90%|████████▉ | 449/500 [17:04<01:56,  2.29s/it, loss=1.06]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all car objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all car objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  90%|█████████ | 450/500 [17:06<01:54,  2.29s/it, loss=0.434]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all small umbrella objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all small umbrella objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  90%|█████████ | 451/500 [17:09<01:52,  2.29s/it, loss=0.217]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment oval chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment oval chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  90%|█████████ | 452/500 [17:11<01:49,  2.29s/it, loss=0.689]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all white sink in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all white sink in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  91%|█████████ | 453/500 [17:13<01:47,  2.29s/it, loss=0.286]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  91%|█████████ | 454/500 [17:16<01:45,  2.29s/it, loss=1.91] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment square bench']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment square bench']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  91%|█████████ | 455/500 [17:18<01:42,  2.29s/it, loss=2.41]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  91%|█████████ | 456/500 [17:20<01:40,  2.28s/it, loss=2.48]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all elephant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all elephant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  91%|█████████▏| 457/500 [17:22<01:37,  2.28s/it, loss=0.692]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all large mouse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all large mouse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  92%|█████████▏| 458/500 [17:25<01:35,  2.27s/it, loss=0.187]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  92%|█████████▏| 459/500 [17:27<01:33,  2.27s/it, loss=3.49] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  92%|█████████▏| 460/500 [17:29<01:30,  2.27s/it, loss=2.68]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all chair regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all chair regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  92%|█████████▏| 461/500 [17:31<01:28,  2.28s/it, loss=0.275]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  92%|█████████▏| 462/500 [17:34<01:26,  2.28s/it, loss=1.45] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all horse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all horse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  93%|█████████▎| 463/500 [17:36<01:24,  2.28s/it, loss=3.05]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment green airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment green airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  93%|█████████▎| 464/500 [17:38<01:21,  2.28s/it, loss=2.92]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all circular dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all circular dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  93%|█████████▎| 465/500 [17:41<01:19,  2.28s/it, loss=0.496]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all bed']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all bed']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  93%|█████████▎| 466/500 [17:43<01:17,  2.28s/it, loss=6.82] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  93%|█████████▎| 467/500 [17:45<01:15,  2.28s/it, loss=3.93]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  94%|█████████▎| 468/500 [17:47<01:12,  2.28s/it, loss=1.65]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all square giraffe regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all square giraffe regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  94%|█████████▍| 469/500 [17:50<01:10,  2.28s/it, loss=3.5] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  94%|█████████▍| 470/500 [17:52<01:08,  2.28s/it, loss=1.21]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  94%|█████████▍| 471/500 [17:54<01:06,  2.29s/it, loss=0.351]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all toilet objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all toilet objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  94%|█████████▍| 472/500 [17:57<01:03,  2.29s/it, loss=1.2]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all dining table']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all dining table']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  95%|█████████▍| 473/500 [17:59<01:01,  2.28s/it, loss=0.164]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  95%|█████████▍| 474/500 [18:01<00:59,  2.28s/it, loss=0.63] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  95%|█████████▌| 475/500 [18:03<00:57,  2.28s/it, loss=2.21]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every purple toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every purple toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  95%|█████████▌| 476/500 [18:06<00:54,  2.28s/it, loss=1.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all rectangular traffic light from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all rectangular traffic light from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  95%|█████████▌| 477/500 [18:08<00:52,  2.28s/it, loss=0.802]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  96%|█████████▌| 478/500 [18:10<00:50,  2.28s/it, loss=2.19] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every laptop']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every laptop']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  96%|█████████▌| 479/500 [18:12<00:47,  2.28s/it, loss=2.96]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  96%|█████████▌| 480/500 [18:15<00:45,  2.28s/it, loss=1.31]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all dog in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all dog in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  96%|█████████▌| 481/500 [18:17<00:43,  2.29s/it, loss=2.45]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment yellow giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment yellow giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  96%|█████████▋| 482/500 [18:19<00:41,  2.29s/it, loss=1.41]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every silver dining table']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every silver dining table']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  97%|█████████▋| 483/500 [18:22<00:38,  2.29s/it, loss=2.56]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all cat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all cat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  97%|█████████▋| 484/500 [18:24<00:36,  2.28s/it, loss=0.622]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bus objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bus objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  97%|█████████▋| 485/500 [18:26<00:34,  2.29s/it, loss=0.609]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all horse regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all horse regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  97%|█████████▋| 486/500 [18:28<00:31,  2.28s/it, loss=3.75] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bottle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bottle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  97%|█████████▋| 487/500 [18:31<00:29,  2.28s/it, loss=0.583]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all giraffe objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all giraffe objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  98%|█████████▊| 488/500 [18:33<00:27,  2.28s/it, loss=1.08] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all round clock regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all round clock regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  98%|█████████▊| 489/500 [18:35<00:25,  2.28s/it, loss=2.74]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all car objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all car objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  98%|█████████▊| 490/500 [18:38<00:22,  2.28s/it, loss=1.71]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  98%|█████████▊| 491/500 [18:40<00:20,  2.28s/it, loss=2.11]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  98%|█████████▊| 492/500 [18:42<00:18,  2.28s/it, loss=0.412]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all wide frisbee from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all wide frisbee from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  99%|█████████▊| 493/500 [18:44<00:15,  2.28s/it, loss=0.0666]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  99%|█████████▉| 494/500 [18:47<00:13,  2.28s/it, loss=0.906] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  99%|█████████▉| 495/500 [18:49<00:11,  2.28s/it, loss=3.05] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all train in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all train in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  99%|█████████▉| 496/500 [18:51<00:09,  2.28s/it, loss=2.01]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  99%|█████████▉| 497/500 [18:54<00:06,  2.28s/it, loss=6.07]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|█████████▉| 498/500 [18:56<00:04,  2.28s/it, loss=1.76]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|█████████▉| 499/500 [18:58<00:02,  2.28s/it, loss=1.95]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 500/500 [19:00<00:00,  2.28s/it, loss=0.252]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\nEpoch 1/2, Average Loss: 1.7129\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":" ✔️Saved checkpoint to /mnt/data/checkpoints/checkpoint_epoch_0.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   0%|          | 0/500 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all sink regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all sink regions']\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"LoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   0%|          | 1/500 [00:02<21:01,  2.53s/it, loss=0.396]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   0%|          | 2/500 [00:04<19:37,  2.37s/it, loss=1.44] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all backpack objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all backpack objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   1%|          | 3/500 [00:07<19:08,  2.31s/it, loss=2.31]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all square tie regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all square tie regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   1%|          | 4/500 [00:09<18:58,  2.30s/it, loss=3.6] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   1%|          | 5/500 [00:11<18:54,  2.29s/it, loss=2.3]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all teddy bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all teddy bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   1%|          | 6/500 [00:13<18:53,  2.29s/it, loss=0.911]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all toilet regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all toilet regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   1%|▏         | 7/500 [00:16<18:53,  2.30s/it, loss=1.79] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   2%|▏         | 8/500 [00:18<18:53,  2.30s/it, loss=0.925]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bird in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bird in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   2%|▏         | 9/500 [00:20<18:53,  2.31s/it, loss=1.58] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   2%|▏         | 10/500 [00:23<18:52,  2.31s/it, loss=0.94]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all tv in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all tv in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   2%|▏         | 11/500 [00:25<18:55,  2.32s/it, loss=2.02]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all potted plant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all potted plant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   2%|▏         | 12/500 [00:27<18:53,  2.32s/it, loss=3.12]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all dog regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all dog regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   3%|▎         | 13/500 [00:30<18:51,  2.32s/it, loss=2.06]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all suitcase regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all suitcase regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   3%|▎         | 14/500 [00:32<18:48,  2.32s/it, loss=0.799]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all silver cow objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all silver cow objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   3%|▎         | 15/500 [00:34<18:44,  2.32s/it, loss=0.914]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment oval toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment oval toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   3%|▎         | 16/500 [00:37<18:39,  2.31s/it, loss=0.761]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all boat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all boat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   3%|▎         | 17/500 [00:39<18:35,  2.31s/it, loss=2.02] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all tie in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all tie in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   4%|▎         | 18/500 [00:41<18:30,  2.30s/it, loss=0.982]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all tv objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all tv objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   4%|▍         | 19/500 [00:43<18:25,  2.30s/it, loss=0.776]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   4%|▍         | 20/500 [00:46<18:20,  2.29s/it, loss=1.22] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all motorcycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all motorcycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   4%|▍         | 21/500 [00:48<18:20,  2.30s/it, loss=0.233]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all red bicycle in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all red bicycle in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   4%|▍         | 22/500 [00:50<18:16,  2.29s/it, loss=1.02] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   5%|▍         | 23/500 [00:53<18:11,  2.29s/it, loss=1.51]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all square car objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all square car objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   5%|▍         | 24/500 [00:55<18:08,  2.29s/it, loss=0.796]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all elephant from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all elephant from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   5%|▌         | 25/500 [00:57<18:04,  2.28s/it, loss=1.2]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   5%|▌         | 26/500 [00:59<17:58,  2.28s/it, loss=1.94]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all chair regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all chair regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   5%|▌         | 27/500 [01:02<17:55,  2.27s/it, loss=1.53]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment stop sign']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment stop sign']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   6%|▌         | 28/500 [01:04<17:51,  2.27s/it, loss=0.837]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all truck regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all truck regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   6%|▌         | 29/500 [01:06<17:47,  2.27s/it, loss=0.426]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all potted plant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all potted plant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   6%|▌         | 30/500 [01:08<17:43,  2.26s/it, loss=0.485]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all rectangular person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all rectangular person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   6%|▌         | 31/500 [01:11<17:40,  2.26s/it, loss=0.506]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all circular traffic light regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all circular traffic light regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   6%|▋         | 32/500 [01:13<17:35,  2.25s/it, loss=3.25] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   7%|▋         | 33/500 [01:15<17:31,  2.25s/it, loss=3.12]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all silver bird regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all silver bird regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   7%|▋         | 34/500 [01:17<17:30,  2.25s/it, loss=3.6] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all giraffe in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all giraffe in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   7%|▋         | 35/500 [01:20<17:26,  2.25s/it, loss=0.91]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment suitcase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment suitcase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   7%|▋         | 36/500 [01:22<17:24,  2.25s/it, loss=2.21]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bird regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bird regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   7%|▋         | 37/500 [01:24<17:22,  2.25s/it, loss=1.18]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   8%|▊         | 38/500 [01:26<17:20,  2.25s/it, loss=0.695]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every microwave']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every microwave']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   8%|▊         | 39/500 [01:29<17:20,  2.26s/it, loss=0.788]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   8%|▊         | 40/500 [01:31<17:18,  2.26s/it, loss=2.75] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   8%|▊         | 41/500 [01:33<17:20,  2.27s/it, loss=0.195]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all donut in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all donut in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   8%|▊         | 42/500 [01:36<17:17,  2.27s/it, loss=1.48] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment square vase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment square vase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   9%|▊         | 43/500 [01:38<17:14,  2.26s/it, loss=0.918]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   9%|▉         | 44/500 [01:40<17:12,  2.27s/it, loss=3.76] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all oven objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all oven objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   9%|▉         | 45/500 [01:42<17:09,  2.26s/it, loss=0.648]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all zebra in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all zebra in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   9%|▉         | 46/500 [01:45<17:03,  2.26s/it, loss=0.184]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment silver person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment silver person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   9%|▉         | 47/500 [01:47<17:01,  2.26s/it, loss=0.682]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all triangular cow objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all triangular cow objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  10%|▉         | 48/500 [01:49<16:58,  2.25s/it, loss=2.04] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  10%|▉         | 49/500 [01:51<16:55,  2.25s/it, loss=0.824]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  10%|█         | 50/500 [01:54<16:53,  2.25s/it, loss=1.06] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  10%|█         | 51/500 [01:56<16:53,  2.26s/it, loss=5.62]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all horse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all horse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  10%|█         | 52/500 [01:58<16:52,  2.26s/it, loss=0.331]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  11%|█         | 53/500 [02:00<16:49,  2.26s/it, loss=3.46] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all toothbrush in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all toothbrush in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  11%|█         | 54/500 [02:03<16:48,  2.26s/it, loss=0.502]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment triangular person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment triangular person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  11%|█         | 55/500 [02:05<16:47,  2.26s/it, loss=0.344]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all green bottle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all green bottle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  11%|█         | 56/500 [02:07<16:45,  2.26s/it, loss=0.23] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all black elephant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all black elephant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  11%|█▏        | 57/500 [02:09<16:43,  2.27s/it, loss=0.25]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  12%|█▏        | 58/500 [02:12<16:40,  2.26s/it, loss=1.32]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  12%|█▏        | 59/500 [02:14<16:38,  2.26s/it, loss=6.54]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bicycle regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bicycle regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  12%|█▏        | 60/500 [02:16<16:36,  2.26s/it, loss=1.6] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment stop sign']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment stop sign']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  12%|█▏        | 61/500 [02:19<16:37,  2.27s/it, loss=3.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all couch in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all couch in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  12%|█▏        | 62/500 [02:21<16:34,  2.27s/it, loss=3.07]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment square bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment square bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  13%|█▎        | 63/500 [02:23<16:30,  2.27s/it, loss=2.84]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  13%|█▎        | 64/500 [02:25<16:27,  2.26s/it, loss=0.278]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment triangular giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment triangular giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  13%|█▎        | 65/500 [02:28<16:25,  2.27s/it, loss=0.73] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all book']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all book']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  13%|█▎        | 66/500 [02:30<16:23,  2.27s/it, loss=0.462]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all elephant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all elephant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  13%|█▎        | 67/500 [02:32<16:21,  2.27s/it, loss=1.84] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all fire hydrant from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all fire hydrant from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  14%|█▎        | 68/500 [02:34<16:19,  2.27s/it, loss=2.43]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all motorcycle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all motorcycle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  14%|█▍        | 69/500 [02:37<16:17,  2.27s/it, loss=1.96]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  14%|█▍        | 70/500 [02:39<16:14,  2.27s/it, loss=3.89]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all long person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all long person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  14%|█▍        | 71/500 [02:41<16:15,  2.27s/it, loss=0.769]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  14%|█▍        | 72/500 [02:43<16:14,  2.28s/it, loss=0.48] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  15%|█▍        | 73/500 [02:46<16:10,  2.27s/it, loss=4.72]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all tall skateboard objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all tall skateboard objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  15%|█▍        | 74/500 [02:48<16:06,  2.27s/it, loss=0.127]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment orange boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment orange boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  15%|█▌        | 75/500 [02:50<16:04,  2.27s/it, loss=5.34] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  15%|█▌        | 76/500 [02:53<16:01,  2.27s/it, loss=3.61]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  15%|█▌        | 77/500 [02:55<15:59,  2.27s/it, loss=1.84]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  16%|█▌        | 78/500 [02:57<15:58,  2.27s/it, loss=2.19]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  16%|█▌        | 79/500 [02:59<15:54,  2.27s/it, loss=2.76]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all traffic light from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all traffic light from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  16%|█▌        | 80/500 [03:02<15:51,  2.27s/it, loss=0.467]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all dog in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all dog in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  16%|█▌        | 81/500 [03:04<15:52,  2.27s/it, loss=1.45] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all mouse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all mouse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  16%|█▋        | 82/500 [03:06<15:52,  2.28s/it, loss=0.61]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all small car regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all small car regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  17%|█▋        | 83/500 [03:08<15:49,  2.28s/it, loss=0.666]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all brown cat objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all brown cat objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  17%|█▋        | 84/500 [03:11<15:47,  2.28s/it, loss=1.86] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  17%|█▋        | 85/500 [03:13<15:45,  2.28s/it, loss=0.766]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment dining table']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment dining table']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  17%|█▋        | 86/500 [03:15<15:43,  2.28s/it, loss=7.79] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  17%|█▋        | 87/500 [03:18<15:38,  2.27s/it, loss=2.92]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every oval giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every oval giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  18%|█▊        | 88/500 [03:20<15:36,  2.27s/it, loss=2.32]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment stop sign']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment stop sign']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  18%|█▊        | 89/500 [03:22<15:34,  2.27s/it, loss=0.438]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  18%|█▊        | 90/500 [03:24<15:32,  2.27s/it, loss=1.39] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment book']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment book']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  18%|█▊        | 91/500 [03:27<15:33,  2.28s/it, loss=0.394]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every triangular giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every triangular giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  18%|█▊        | 92/500 [03:29<15:30,  2.28s/it, loss=2.06] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  19%|█▊        | 93/500 [03:31<15:27,  2.28s/it, loss=1.95]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all gray clock objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all gray clock objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  19%|█▉        | 94/500 [03:34<15:24,  2.28s/it, loss=1.42]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment vase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment vase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  19%|█▉        | 95/500 [03:36<15:23,  2.28s/it, loss=0.589]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all remote regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all remote regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  19%|█▉        | 96/500 [03:38<15:21,  2.28s/it, loss=0.756]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every sheep']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every sheep']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  19%|█▉        | 97/500 [03:40<15:18,  2.28s/it, loss=3.05] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all black person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all black person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  20%|█▉        | 98/500 [03:43<15:15,  2.28s/it, loss=1.28]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  20%|█▉        | 99/500 [03:45<15:13,  2.28s/it, loss=0.768]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  20%|██        | 100/500 [03:47<15:11,  2.28s/it, loss=3.52]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all elephant from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all elephant from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  20%|██        | 101/500 [03:49<15:10,  2.28s/it, loss=0.468]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  20%|██        | 102/500 [03:52<15:07,  2.28s/it, loss=1.79] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every handbag']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every handbag']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  21%|██        | 103/500 [03:54<15:05,  2.28s/it, loss=0.561]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  21%|██        | 104/500 [03:56<15:02,  2.28s/it, loss=3.84] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  21%|██        | 105/500 [03:59<14:58,  2.28s/it, loss=4.98]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  21%|██        | 106/500 [04:01<14:57,  2.28s/it, loss=0.396]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all cup in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all cup in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  21%|██▏       | 107/500 [04:03<14:54,  2.28s/it, loss=0.446]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment red giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment red giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  22%|██▏       | 108/500 [04:05<14:52,  2.28s/it, loss=0.978]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  22%|██▏       | 109/500 [04:08<14:49,  2.28s/it, loss=1.83] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bench from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bench from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  22%|██▏       | 110/500 [04:10<14:47,  2.28s/it, loss=0.465]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment orange zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment orange zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  22%|██▏       | 111/500 [04:12<14:48,  2.28s/it, loss=3.5]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  22%|██▏       | 112/500 [04:15<14:45,  2.28s/it, loss=0.276]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  23%|██▎       | 113/500 [04:17<14:41,  2.28s/it, loss=4.99] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bottle in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bottle in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  23%|██▎       | 114/500 [04:19<14:38,  2.28s/it, loss=2.6] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all black microwave in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all black microwave in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  23%|██▎       | 115/500 [04:21<14:36,  2.28s/it, loss=0.46]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment sink']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment sink']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  23%|██▎       | 116/500 [04:24<14:34,  2.28s/it, loss=0.608]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all car regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all car regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  23%|██▎       | 117/500 [04:26<14:31,  2.27s/it, loss=2.97] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  24%|██▎       | 118/500 [04:28<14:28,  2.27s/it, loss=0.702]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all handbag regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all handbag regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  24%|██▍       | 119/500 [04:30<14:27,  2.28s/it, loss=0.262]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all small frisbee in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all small frisbee in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  24%|██▍       | 120/500 [04:33<14:24,  2.28s/it, loss=1.01] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all elephant from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all elephant from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  24%|██▍       | 121/500 [04:35<14:26,  2.29s/it, loss=5.68]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  24%|██▍       | 122/500 [04:37<14:24,  2.29s/it, loss=1.61]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment oval bicycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment oval bicycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  25%|██▍       | 123/500 [04:40<14:21,  2.28s/it, loss=0.456]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every brown person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every brown person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  25%|██▍       | 124/500 [04:42<14:18,  2.28s/it, loss=0.525]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  25%|██▌       | 125/500 [04:44<14:15,  2.28s/it, loss=3.08] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all elephant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all elephant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  25%|██▌       | 126/500 [04:46<14:12,  2.28s/it, loss=1.07]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all book objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all book objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  25%|██▌       | 127/500 [04:49<14:09,  2.28s/it, loss=0.531]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every tall horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every tall horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  26%|██▌       | 128/500 [04:51<14:07,  2.28s/it, loss=2.81] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all wide horse regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all wide horse regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  26%|██▌       | 129/500 [04:53<14:04,  2.28s/it, loss=0.519]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  26%|██▌       | 130/500 [04:56<14:01,  2.27s/it, loss=3.2]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment red potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment red potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  26%|██▌       | 131/500 [04:58<14:00,  2.28s/it, loss=3.67]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all brown umbrella regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all brown umbrella regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  26%|██▋       | 132/500 [05:00<13:58,  2.28s/it, loss=0.935]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  27%|██▋       | 133/500 [05:02<13:57,  2.28s/it, loss=1.69] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  27%|██▋       | 134/500 [05:05<13:55,  2.28s/it, loss=2.03]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment tv']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment tv']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  27%|██▋       | 135/500 [05:07<13:50,  2.28s/it, loss=2.8] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every red potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every red potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  27%|██▋       | 136/500 [05:09<13:49,  2.28s/it, loss=0.492]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all wide sink from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all wide sink from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  27%|██▋       | 137/500 [05:11<13:46,  2.28s/it, loss=0.255]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  28%|██▊       | 138/500 [05:14<13:43,  2.28s/it, loss=0.134]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment handbag']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment handbag']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  28%|██▊       | 139/500 [05:16<13:41,  2.28s/it, loss=0.28] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all airplane regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all airplane regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  28%|██▊       | 140/500 [05:18<13:39,  2.28s/it, loss=3.42]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  28%|██▊       | 141/500 [05:21<13:39,  2.28s/it, loss=1.44]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all tv']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all tv']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  28%|██▊       | 142/500 [05:23<13:37,  2.28s/it, loss=2]   ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bird regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bird regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  29%|██▊       | 143/500 [05:25<13:33,  2.28s/it, loss=1.52]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bicycle objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bicycle objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  29%|██▉       | 144/500 [05:27<13:31,  2.28s/it, loss=0.573]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all orange motorcycle in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all orange motorcycle in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  29%|██▉       | 145/500 [05:30<13:26,  2.27s/it, loss=0.238]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all wide zebra regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all wide zebra regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  29%|██▉       | 146/500 [05:32<13:23,  2.27s/it, loss=1.96] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment bicycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment bicycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  29%|██▉       | 147/500 [05:34<13:21,  2.27s/it, loss=1.32]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all fire hydrant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all fire hydrant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  30%|██▉       | 148/500 [05:37<13:19,  2.27s/it, loss=1.18]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bench objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bench objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  30%|██▉       | 149/500 [05:39<13:17,  2.27s/it, loss=0.608]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  30%|███       | 150/500 [05:41<13:15,  2.27s/it, loss=1.07] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all cup regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all cup regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  30%|███       | 151/500 [05:43<13:14,  2.28s/it, loss=1.86]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment frisbee']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment frisbee']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  30%|███       | 152/500 [05:46<13:12,  2.28s/it, loss=0.851]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment long tv']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment long tv']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  31%|███       | 153/500 [05:48<13:10,  2.28s/it, loss=2.93] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  31%|███       | 154/500 [05:50<13:07,  2.28s/it, loss=2.53]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all triangular giraffe from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all triangular giraffe from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  31%|███       | 155/500 [05:52<13:05,  2.28s/it, loss=2.16]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all boat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all boat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  31%|███       | 156/500 [05:55<13:03,  2.28s/it, loss=2.37]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all car regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all car regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  31%|███▏      | 157/500 [05:57<13:00,  2.28s/it, loss=1.58]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  32%|███▏      | 158/500 [05:59<12:57,  2.27s/it, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all sink objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all sink objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  32%|███▏      | 159/500 [06:02<12:54,  2.27s/it, loss=0.493]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all potted plant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all potted plant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  32%|███▏      | 160/500 [06:04<12:52,  2.27s/it, loss=0.525]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all cat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all cat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  32%|███▏      | 161/500 [06:06<12:53,  2.28s/it, loss=0.849]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  32%|███▏      | 162/500 [06:08<12:51,  2.28s/it, loss=1.23] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  33%|███▎      | 163/500 [06:11<12:47,  2.28s/it, loss=1.8] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment white remote']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment white remote']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  33%|███▎      | 164/500 [06:13<12:45,  2.28s/it, loss=1.25]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all sink objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all sink objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  33%|███▎      | 165/500 [06:15<12:41,  2.27s/it, loss=2.16]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  33%|███▎      | 166/500 [06:18<12:40,  2.28s/it, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  33%|███▎      | 167/500 [06:20<12:38,  2.28s/it, loss=0.534]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment round elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment round elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  34%|███▎      | 168/500 [06:22<12:35,  2.28s/it, loss=1.25] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all fire hydrant objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all fire hydrant objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  34%|███▍      | 169/500 [06:24<12:31,  2.27s/it, loss=0.412]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  34%|███▍      | 170/500 [06:27<12:29,  2.27s/it, loss=0.381]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bowl regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bowl regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  34%|███▍      | 171/500 [06:29<12:29,  2.28s/it, loss=0.844]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all dining table objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all dining table objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  34%|███▍      | 172/500 [06:31<12:27,  2.28s/it, loss=0.859]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment circular keyboard']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment circular keyboard']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  35%|███▍      | 173/500 [06:33<12:24,  2.28s/it, loss=2.77] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bottle in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bottle in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  35%|███▍      | 174/500 [06:36<12:22,  2.28s/it, loss=3.67]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all toilet regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all toilet regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  35%|███▌      | 175/500 [06:38<12:19,  2.28s/it, loss=0.713]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all giraffe in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all giraffe in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  35%|███▌      | 176/500 [06:40<12:18,  2.28s/it, loss=1.35] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all backpack in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all backpack in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  35%|███▌      | 177/500 [06:43<12:16,  2.28s/it, loss=0.629]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment red person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment red person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  36%|███▌      | 178/500 [06:45<12:13,  2.28s/it, loss=3.04] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment motorcycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment motorcycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  36%|███▌      | 179/500 [06:47<12:11,  2.28s/it, loss=0.404]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every clock']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every clock']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  36%|███▌      | 180/500 [06:49<12:08,  2.28s/it, loss=0.515]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every pink person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every pink person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  36%|███▌      | 181/500 [06:52<12:08,  2.28s/it, loss=2.29] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  36%|███▋      | 182/500 [06:54<12:06,  2.28s/it, loss=2.72]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all silver motorcycle from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all silver motorcycle from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  37%|███▋      | 183/500 [06:56<12:03,  2.28s/it, loss=0.676]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all car from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all car from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  37%|███▋      | 184/500 [06:59<11:59,  2.28s/it, loss=2.12] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  37%|███▋      | 185/500 [07:01<11:57,  2.28s/it, loss=0.196]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  37%|███▋      | 186/500 [07:03<11:55,  2.28s/it, loss=1.88] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all tall bird in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all tall bird in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  37%|███▋      | 187/500 [07:05<11:53,  2.28s/it, loss=0.646]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bicycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bicycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  38%|███▊      | 188/500 [07:08<11:51,  2.28s/it, loss=0.25] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every orange vase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every orange vase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  38%|███▊      | 189/500 [07:10<11:49,  2.28s/it, loss=0.284]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all cup from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all cup from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  38%|███▊      | 190/500 [07:12<11:47,  2.28s/it, loss=0.685]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bench objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bench objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  38%|███▊      | 191/500 [07:14<11:46,  2.29s/it, loss=0.995]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all rectangular person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all rectangular person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  38%|███▊      | 192/500 [07:17<11:45,  2.29s/it, loss=0.848]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all laptop in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all laptop in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  39%|███▊      | 193/500 [07:19<11:42,  2.29s/it, loss=2.35] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  39%|███▉      | 194/500 [07:21<11:39,  2.29s/it, loss=6.81]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  39%|███▉      | 195/500 [07:24<11:35,  2.28s/it, loss=3.14]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all tall stop sign objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all tall stop sign objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  39%|███▉      | 196/500 [07:26<11:33,  2.28s/it, loss=3.57]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all blue sheep from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all blue sheep from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  39%|███▉      | 197/500 [07:28<11:31,  2.28s/it, loss=3.29]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all elephant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all elephant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  40%|███▉      | 198/500 [07:30<11:28,  2.28s/it, loss=4.96]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  40%|███▉      | 199/500 [07:33<11:26,  2.28s/it, loss=2.08]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  40%|████      | 200/500 [07:35<11:24,  2.28s/it, loss=0.195]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  40%|████      | 201/500 [07:37<11:24,  2.29s/it, loss=0.5]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment black person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment black person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  40%|████      | 202/500 [07:40<11:22,  2.29s/it, loss=1.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment rectangular person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment rectangular person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  41%|████      | 203/500 [07:42<11:19,  2.29s/it, loss=1.65]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment thin zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment thin zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  41%|████      | 204/500 [07:44<11:16,  2.29s/it, loss=3.18]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment purple horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment purple horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  41%|████      | 205/500 [07:46<11:12,  2.28s/it, loss=1.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all chair in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all chair in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  41%|████      | 206/500 [07:49<11:11,  2.28s/it, loss=1.18]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all round boat regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all round boat regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  41%|████▏     | 207/500 [07:51<11:07,  2.28s/it, loss=2.49]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  42%|████▏     | 208/500 [07:53<11:04,  2.28s/it, loss=2.86]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all bench']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all bench']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  42%|████▏     | 209/500 [07:56<11:03,  2.28s/it, loss=0.309]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all black tv objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all black tv objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  42%|████▏     | 210/500 [07:58<11:00,  2.28s/it, loss=0.507]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all tv objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all tv objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  42%|████▏     | 211/500 [08:00<10:59,  2.28s/it, loss=0.478]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all blue tie']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all blue tie']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  42%|████▏     | 212/500 [08:02<10:58,  2.28s/it, loss=0.61] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment green person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment green person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  43%|████▎     | 213/500 [08:05<10:54,  2.28s/it, loss=1.39]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  43%|████▎     | 214/500 [08:07<10:51,  2.28s/it, loss=4.59]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  43%|████▎     | 215/500 [08:09<10:48,  2.28s/it, loss=4.76]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all car regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all car regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  43%|████▎     | 216/500 [08:12<10:45,  2.27s/it, loss=2.93]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  43%|████▎     | 217/500 [08:14<10:43,  2.27s/it, loss=1.37]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all book in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all book in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  44%|████▎     | 218/500 [08:16<10:41,  2.27s/it, loss=0.725]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  44%|████▍     | 219/500 [08:18<10:38,  2.27s/it, loss=1.91] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bench in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bench in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  44%|████▍     | 220/500 [08:21<10:36,  2.27s/it, loss=0.861]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  44%|████▍     | 221/500 [08:23<10:35,  2.28s/it, loss=1.96] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all suitcase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all suitcase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  44%|████▍     | 222/500 [08:25<10:33,  2.28s/it, loss=1.33]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  45%|████▍     | 223/500 [08:27<10:29,  2.27s/it, loss=0.649]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all dog regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all dog regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  45%|████▍     | 224/500 [08:30<10:26,  2.27s/it, loss=1.84] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  45%|████▌     | 225/500 [08:32<10:24,  2.27s/it, loss=2.28]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment red broccoli']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment red broccoli']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  45%|████▌     | 226/500 [08:34<10:22,  2.27s/it, loss=1.46]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all orange umbrella objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all orange umbrella objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  45%|████▌     | 227/500 [08:37<10:19,  2.27s/it, loss=1.12]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all sink in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all sink in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  46%|████▌     | 228/500 [08:39<10:17,  2.27s/it, loss=0.502]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all round bird in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all round bird in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  46%|████▌     | 229/500 [08:41<10:15,  2.27s/it, loss=3.24] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all elephant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all elephant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  46%|████▌     | 230/500 [08:43<10:12,  2.27s/it, loss=2.2] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment handbag']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment handbag']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  46%|████▌     | 231/500 [08:46<10:12,  2.28s/it, loss=0.652]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all tie in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all tie in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  46%|████▋     | 232/500 [08:48<10:09,  2.27s/it, loss=2.22] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  47%|████▋     | 233/500 [08:50<10:06,  2.27s/it, loss=3.58]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all bottle objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all bottle objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  47%|████▋     | 234/500 [08:52<10:04,  2.27s/it, loss=0.823]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all orange boat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all orange boat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  47%|████▋     | 235/500 [08:55<10:02,  2.28s/it, loss=1.71] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all circular person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all circular person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  47%|████▋     | 236/500 [08:57<09:59,  2.27s/it, loss=2.15]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all elephant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all elephant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  47%|████▋     | 237/500 [08:59<09:56,  2.27s/it, loss=3.57]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all dining table regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all dining table regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  48%|████▊     | 238/500 [09:02<09:55,  2.27s/it, loss=0.116]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every brown dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every brown dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  48%|████▊     | 239/500 [09:04<09:52,  2.27s/it, loss=0.913]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every tall elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every tall elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  48%|████▊     | 240/500 [09:06<09:50,  2.27s/it, loss=6.36] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  48%|████▊     | 241/500 [09:08<09:50,  2.28s/it, loss=0.246]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  48%|████▊     | 242/500 [09:11<09:48,  2.28s/it, loss=2.08] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all large horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all large horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  49%|████▊     | 243/500 [09:13<09:45,  2.28s/it, loss=1.29]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  49%|████▉     | 244/500 [09:15<09:42,  2.28s/it, loss=1.43]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  49%|████▉     | 245/500 [09:17<09:40,  2.28s/it, loss=0.873]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bench from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bench from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  49%|████▉     | 246/500 [09:20<09:37,  2.27s/it, loss=2.04] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment yellow cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment yellow cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  49%|████▉     | 247/500 [09:22<09:35,  2.27s/it, loss=3.43]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment umbrella']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment umbrella']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  50%|████▉     | 248/500 [09:24<09:32,  2.27s/it, loss=0.426]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all round bus regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all round bus regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  50%|████▉     | 249/500 [09:27<09:29,  2.27s/it, loss=4.62] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all sink objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all sink objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  50%|█████     | 250/500 [09:29<09:28,  2.27s/it, loss=1.9] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment square suitcase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment square suitcase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  50%|█████     | 251/500 [09:31<09:27,  2.28s/it, loss=0.803]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  50%|█████     | 252/500 [09:33<09:24,  2.28s/it, loss=2.07] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  51%|█████     | 253/500 [09:36<09:22,  2.28s/it, loss=0.807]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all silver boat objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all silver boat objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  51%|█████     | 254/500 [09:38<09:19,  2.28s/it, loss=4.52] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all blue dog in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all blue dog in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  51%|█████     | 255/500 [09:40<09:16,  2.27s/it, loss=3.02]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all rectangular boat regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all rectangular boat regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  51%|█████     | 256/500 [09:42<09:13,  2.27s/it, loss=1.42]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  51%|█████▏    | 257/500 [09:45<09:11,  2.27s/it, loss=0.636]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all laptop regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all laptop regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  52%|█████▏    | 258/500 [09:47<09:08,  2.27s/it, loss=2.87] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  52%|█████▏    | 259/500 [09:49<09:06,  2.27s/it, loss=4.26]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  52%|█████▏    | 260/500 [09:52<09:04,  2.27s/it, loss=0.147]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  52%|█████▏    | 261/500 [09:54<09:04,  2.28s/it, loss=0.0714]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment circular elephant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment circular elephant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  52%|█████▏    | 262/500 [09:56<09:01,  2.27s/it, loss=0.315] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all large bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all large bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  53%|█████▎    | 263/500 [09:58<08:58,  2.27s/it, loss=1.33] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all orange spoon']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all orange spoon']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  53%|█████▎    | 264/500 [10:01<08:56,  2.27s/it, loss=0.733]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all wide parking meter objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all wide parking meter objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  53%|█████▎    | 265/500 [10:03<08:53,  2.27s/it, loss=2.37] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  53%|█████▎    | 266/500 [10:05<08:50,  2.27s/it, loss=2.15]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all traffic light in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all traffic light in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  53%|█████▎    | 267/500 [10:07<08:48,  2.27s/it, loss=0.45]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  54%|█████▎    | 268/500 [10:10<08:46,  2.27s/it, loss=0.477]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all black cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all black cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  54%|█████▍    | 269/500 [10:12<08:43,  2.27s/it, loss=1.95] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all square handbag in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all square handbag in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  54%|█████▍    | 270/500 [10:14<08:41,  2.27s/it, loss=0.35]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment frisbee']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment frisbee']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  54%|█████▍    | 271/500 [10:17<08:41,  2.28s/it, loss=0.719]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all boat objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all boat objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  54%|█████▍    | 272/500 [10:19<08:38,  2.28s/it, loss=2]    ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  55%|█████▍    | 273/500 [10:21<08:35,  2.27s/it, loss=1.38]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all bus']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all bus']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  55%|█████▍    | 274/500 [10:23<08:33,  2.27s/it, loss=1.61]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  55%|█████▌    | 275/500 [10:26<08:29,  2.27s/it, loss=3.69]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment tie']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment tie']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  55%|█████▌    | 276/500 [10:28<08:27,  2.27s/it, loss=2.38]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all train in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all train in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  55%|█████▌    | 277/500 [10:30<08:25,  2.27s/it, loss=3.37]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  56%|█████▌    | 278/500 [10:32<08:24,  2.27s/it, loss=2.3] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  56%|█████▌    | 279/500 [10:35<08:22,  2.27s/it, loss=0.735]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment orange']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment orange']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  56%|█████▌    | 280/500 [10:37<08:19,  2.27s/it, loss=0.895]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  56%|█████▌    | 281/500 [10:39<08:18,  2.28s/it, loss=3.29] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  56%|█████▋    | 282/500 [10:41<08:16,  2.28s/it, loss=1.32]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all cat regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all cat regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  57%|█████▋    | 283/500 [10:44<08:13,  2.27s/it, loss=0.298]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all dog objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all dog objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  57%|█████▋    | 284/500 [10:46<08:10,  2.27s/it, loss=2.91] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  57%|█████▋    | 285/500 [10:48<08:07,  2.27s/it, loss=1.29]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bottle regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bottle regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  57%|█████▋    | 286/500 [10:51<08:05,  2.27s/it, loss=0.058]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all sheep in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all sheep in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  57%|█████▋    | 287/500 [10:53<08:02,  2.27s/it, loss=1.32] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment cell phone']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment cell phone']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  58%|█████▊    | 288/500 [10:55<08:00,  2.27s/it, loss=0.189]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all motorcycle regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all motorcycle regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  58%|█████▊    | 289/500 [10:57<07:58,  2.27s/it, loss=3.78] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all bird from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all bird from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  58%|█████▊    | 290/500 [11:00<07:55,  2.26s/it, loss=0.879]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all cat in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all cat in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  58%|█████▊    | 291/500 [11:02<07:54,  2.27s/it, loss=2.26] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bicycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bicycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  58%|█████▊    | 292/500 [11:04<07:52,  2.27s/it, loss=0.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all tv objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all tv objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  59%|█████▊    | 293/500 [11:06<07:50,  2.27s/it, loss=1.9] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all circular dog regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all circular dog regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  59%|█████▉    | 294/500 [11:09<07:47,  2.27s/it, loss=6.4]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all blue person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all blue person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  59%|█████▉    | 295/500 [11:11<07:44,  2.27s/it, loss=1]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  59%|█████▉    | 296/500 [11:13<07:42,  2.27s/it, loss=0.446]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all round car objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all round car objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  59%|█████▉    | 297/500 [11:15<07:40,  2.27s/it, loss=0.433]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every blue banana']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every blue banana']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  60%|█████▉    | 298/500 [11:18<07:38,  2.27s/it, loss=2.79] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  60%|█████▉    | 299/500 [11:20<07:36,  2.27s/it, loss=2.63]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all suitcase regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all suitcase regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  60%|██████    | 300/500 [11:22<07:34,  2.27s/it, loss=3.12]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  60%|██████    | 301/500 [11:25<07:33,  2.28s/it, loss=0.223]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all zebra in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all zebra in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  60%|██████    | 302/500 [11:27<07:30,  2.28s/it, loss=0.579]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  61%|██████    | 303/500 [11:29<07:28,  2.27s/it, loss=3.05] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  61%|██████    | 304/500 [11:31<07:25,  2.27s/it, loss=0.572]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all horse regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all horse regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  61%|██████    | 305/500 [11:34<07:22,  2.27s/it, loss=3.85] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment circular person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment circular person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  61%|██████    | 306/500 [11:36<07:20,  2.27s/it, loss=0.897]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all tv']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all tv']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  61%|██████▏   | 307/500 [11:38<07:17,  2.27s/it, loss=1.03] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  62%|██████▏   | 308/500 [11:40<07:15,  2.27s/it, loss=0.454]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all elephant from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all elephant from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  62%|██████▏   | 309/500 [11:43<07:13,  2.27s/it, loss=0.639]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all wide toilet in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all wide toilet in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  62%|██████▏   | 310/500 [11:45<07:11,  2.27s/it, loss=1.19] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  62%|██████▏   | 311/500 [11:47<07:11,  2.28s/it, loss=0.956]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all square person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all square person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  62%|██████▏   | 312/500 [11:50<07:09,  2.28s/it, loss=1.86] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all round person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all round person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  63%|██████▎   | 313/500 [11:52<07:06,  2.28s/it, loss=1.58]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment frisbee']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment frisbee']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  63%|██████▎   | 314/500 [11:54<07:03,  2.28s/it, loss=0.0987]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all oval chair']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all oval chair']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  63%|██████▎   | 315/500 [11:56<07:00,  2.28s/it, loss=1.03]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment wide person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment wide person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  63%|██████▎   | 316/500 [11:59<06:58,  2.27s/it, loss=1.48]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  63%|██████▎   | 317/500 [12:01<06:56,  2.27s/it, loss=0.496]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment bottle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment bottle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  64%|██████▎   | 318/500 [12:03<06:53,  2.27s/it, loss=0.0477]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment boat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment boat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  64%|██████▍   | 319/500 [12:06<06:51,  2.27s/it, loss=0.602] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all boat regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all boat regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  64%|██████▍   | 320/500 [12:08<06:49,  2.27s/it, loss=3.06] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all cow in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all cow in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  64%|██████▍   | 321/500 [12:10<06:48,  2.28s/it, loss=2.08]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  64%|██████▍   | 322/500 [12:12<06:47,  2.29s/it, loss=0.818]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all orange giraffe regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all orange giraffe regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  65%|██████▍   | 323/500 [12:15<06:44,  2.29s/it, loss=2.34] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all pink bowl']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all pink bowl']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  65%|██████▍   | 324/500 [12:17<06:42,  2.28s/it, loss=0.0999]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  65%|██████▌   | 325/500 [12:19<06:39,  2.28s/it, loss=0.194] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all red elephant objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all red elephant objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  65%|██████▌   | 326/500 [12:22<06:37,  2.28s/it, loss=0.254]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all car from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all car from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  65%|██████▌   | 327/500 [12:24<06:34,  2.28s/it, loss=1.32] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all small horse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all small horse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  66%|██████▌   | 328/500 [12:26<06:32,  2.28s/it, loss=1.23]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  66%|██████▌   | 329/500 [12:28<06:29,  2.28s/it, loss=0.31]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  66%|██████▌   | 330/500 [12:31<06:27,  2.28s/it, loss=3.04]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  66%|██████▌   | 331/500 [12:33<06:27,  2.29s/it, loss=3.16]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  66%|██████▋   | 332/500 [12:35<06:24,  2.29s/it, loss=2.88]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all truck regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all truck regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  67%|██████▋   | 333/500 [12:38<06:22,  2.29s/it, loss=0.859]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment thin giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment thin giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  67%|██████▋   | 334/500 [12:40<06:19,  2.29s/it, loss=3]    ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all yellow cat regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all yellow cat regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  67%|██████▋   | 335/500 [12:42<06:17,  2.29s/it, loss=0.685]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every brown person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every brown person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  67%|██████▋   | 336/500 [12:44<06:15,  2.29s/it, loss=0.389]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all green bicycle']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all green bicycle']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  67%|██████▋   | 337/500 [12:47<06:12,  2.29s/it, loss=1.45] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all stop sign in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all stop sign in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  68%|██████▊   | 338/500 [12:49<06:10,  2.29s/it, loss=0.389]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all car from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all car from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  68%|██████▊   | 339/500 [12:51<06:08,  2.29s/it, loss=0.874]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  68%|██████▊   | 340/500 [12:54<06:05,  2.29s/it, loss=0.76] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  68%|██████▊   | 341/500 [12:56<06:04,  2.29s/it, loss=1.82]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  68%|██████▊   | 342/500 [12:58<06:02,  2.29s/it, loss=0.298]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all fire hydrant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all fire hydrant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  69%|██████▊   | 343/500 [13:00<05:59,  2.29s/it, loss=1.55] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  69%|██████▉   | 344/500 [13:03<05:56,  2.29s/it, loss=0.308]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all car objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all car objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  69%|██████▉   | 345/500 [13:05<05:54,  2.29s/it, loss=1.61] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment white person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment white person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  69%|██████▉   | 346/500 [13:07<05:51,  2.28s/it, loss=3.33]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all traffic light in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all traffic light in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  69%|██████▉   | 347/500 [13:10<05:49,  2.28s/it, loss=2.17]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  70%|██████▉   | 348/500 [13:12<05:46,  2.28s/it, loss=1.04]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all horse regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all horse regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  70%|██████▉   | 349/500 [13:14<05:44,  2.28s/it, loss=3.52]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment banana']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment banana']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  70%|███████   | 350/500 [13:16<05:42,  2.28s/it, loss=1.64]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  70%|███████   | 351/500 [13:19<05:40,  2.29s/it, loss=0.623]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all zebra regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all zebra regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  70%|███████   | 352/500 [13:21<05:38,  2.28s/it, loss=1.62] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  71%|███████   | 353/500 [13:23<05:35,  2.28s/it, loss=3.69]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment oval truck']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment oval truck']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  71%|███████   | 354/500 [13:26<05:33,  2.28s/it, loss=3.75]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  71%|███████   | 355/500 [13:28<05:30,  2.28s/it, loss=0.287]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  71%|███████   | 356/500 [13:30<05:28,  2.28s/it, loss=0.406]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all sheep regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all sheep regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  71%|███████▏  | 357/500 [13:32<05:25,  2.28s/it, loss=1.51] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  72%|███████▏  | 358/500 [13:35<05:23,  2.28s/it, loss=4.9] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  72%|███████▏  | 359/500 [13:37<05:21,  2.28s/it, loss=1.1]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all square car from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all square car from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  72%|███████▏  | 360/500 [13:39<05:19,  2.28s/it, loss=2.52]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all elephant objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all elephant objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  72%|███████▏  | 361/500 [13:42<05:17,  2.29s/it, loss=0.667]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every red sheep']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every red sheep']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  72%|███████▏  | 362/500 [13:44<05:15,  2.28s/it, loss=1.42] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all umbrella in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all umbrella in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  73%|███████▎  | 363/500 [13:46<05:12,  2.28s/it, loss=1.77]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  73%|███████▎  | 364/500 [13:48<05:09,  2.28s/it, loss=1.92]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all tv']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all tv']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  73%|███████▎  | 365/500 [13:51<05:07,  2.28s/it, loss=1.17]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all elephant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all elephant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  73%|███████▎  | 366/500 [13:53<05:05,  2.28s/it, loss=2.56]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  73%|███████▎  | 367/500 [13:55<05:02,  2.27s/it, loss=1.27]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all train objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all train objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  74%|███████▎  | 368/500 [13:57<05:00,  2.27s/it, loss=3.01]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment tall dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment tall dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  74%|███████▍  | 369/500 [14:00<04:58,  2.27s/it, loss=5.82]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment banana']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment banana']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  74%|███████▍  | 370/500 [14:02<04:55,  2.27s/it, loss=2.2] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all horse from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all horse from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  74%|███████▍  | 371/500 [14:04<04:54,  2.28s/it, loss=3.92]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment white toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment white toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  74%|███████▍  | 372/500 [14:07<04:51,  2.28s/it, loss=2.21]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all gray zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all gray zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  75%|███████▍  | 373/500 [14:09<04:49,  2.28s/it, loss=0.764]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all knife in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all knife in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  75%|███████▍  | 374/500 [14:11<04:46,  2.27s/it, loss=0.475]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment thin zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment thin zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  75%|███████▌  | 375/500 [14:13<04:44,  2.27s/it, loss=3.35] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every teddy bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every teddy bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  75%|███████▌  | 376/500 [14:16<04:41,  2.27s/it, loss=1.8] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment train']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment train']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  75%|███████▌  | 377/500 [14:18<04:39,  2.27s/it, loss=3.94]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all zebra objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all zebra objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  76%|███████▌  | 378/500 [14:20<04:37,  2.27s/it, loss=1.55]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment brown sheep']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment brown sheep']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  76%|███████▌  | 379/500 [14:22<04:34,  2.27s/it, loss=0.596]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all hot dog objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all hot dog objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  76%|███████▌  | 380/500 [14:25<04:32,  2.27s/it, loss=2.48] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment square person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment square person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  76%|███████▌  | 381/500 [14:27<04:31,  2.28s/it, loss=0.464]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  76%|███████▋  | 382/500 [14:29<04:29,  2.28s/it, loss=3.02] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  77%|███████▋  | 383/500 [14:32<04:26,  2.28s/it, loss=2]   ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all giraffe in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all giraffe in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  77%|███████▋  | 384/500 [14:34<04:24,  2.28s/it, loss=1.08]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every silver dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every silver dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  77%|███████▋  | 385/500 [14:36<04:21,  2.27s/it, loss=1.08]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  77%|███████▋  | 386/500 [14:38<04:19,  2.27s/it, loss=2.87]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  77%|███████▋  | 387/500 [14:41<04:16,  2.27s/it, loss=8.93]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bowl in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bowl in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  78%|███████▊  | 388/500 [14:43<04:14,  2.27s/it, loss=0.865]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all fire hydrant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all fire hydrant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  78%|███████▊  | 389/500 [14:45<04:12,  2.27s/it, loss=2.03] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all sink']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all sink']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  78%|███████▊  | 390/500 [14:47<04:10,  2.28s/it, loss=0.23]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every orange zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every orange zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  78%|███████▊  | 391/500 [14:50<04:08,  2.28s/it, loss=3.23]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all truck objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all truck objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  78%|███████▊  | 392/500 [14:52<04:06,  2.28s/it, loss=2]   ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  79%|███████▊  | 393/500 [14:54<04:04,  2.28s/it, loss=2.71]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  79%|███████▉  | 394/500 [14:57<04:01,  2.28s/it, loss=4.24]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  79%|███████▉  | 395/500 [14:59<03:59,  2.28s/it, loss=2.36]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all white car from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all white car from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  79%|███████▉  | 396/500 [15:01<03:57,  2.28s/it, loss=0.264]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all suitcase in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all suitcase in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  79%|███████▉  | 397/500 [15:03<03:55,  2.28s/it, loss=5.02] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all gray motorcycle objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all gray motorcycle objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  80%|███████▉  | 398/500 [15:06<03:53,  2.29s/it, loss=6.1] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all car from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all car from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  80%|███████▉  | 399/500 [15:08<03:51,  2.29s/it, loss=0.305]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all sink from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all sink from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  80%|████████  | 400/500 [15:10<03:48,  2.28s/it, loss=1.39] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  80%|████████  | 401/500 [15:13<03:47,  2.29s/it, loss=0.117]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all potted plant regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all potted plant regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  80%|████████  | 402/500 [15:15<03:45,  2.30s/it, loss=1.47] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all circular dining table in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all circular dining table in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  81%|████████  | 403/500 [15:17<03:42,  2.30s/it, loss=0.202]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  81%|████████  | 404/500 [15:20<03:39,  2.29s/it, loss=1.22] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  81%|████████  | 405/500 [15:22<03:37,  2.29s/it, loss=5.99]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  81%|████████  | 406/500 [15:24<03:34,  2.29s/it, loss=0.107]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bus in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bus in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  81%|████████▏ | 407/500 [15:26<03:32,  2.29s/it, loss=4.12] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all tall airplane in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all tall airplane in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  82%|████████▏ | 408/500 [15:29<03:30,  2.29s/it, loss=1.27]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  82%|████████▏ | 409/500 [15:31<03:28,  2.29s/it, loss=1.78]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bicycle regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bicycle regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  82%|████████▏ | 410/500 [15:33<03:26,  2.29s/it, loss=0.549]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  82%|████████▏ | 411/500 [15:36<03:24,  2.29s/it, loss=0.624]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all handbag objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all handbag objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  82%|████████▏ | 412/500 [15:38<03:21,  2.29s/it, loss=0.889]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  83%|████████▎ | 413/500 [15:40<03:19,  2.29s/it, loss=0.778]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  83%|████████▎ | 414/500 [15:42<03:17,  2.29s/it, loss=0.376]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  83%|████████▎ | 415/500 [15:45<03:14,  2.29s/it, loss=0.383]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment round stop sign']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment round stop sign']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  83%|████████▎ | 416/500 [15:47<03:11,  2.28s/it, loss=2.86] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all train objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all train objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  83%|████████▎ | 417/500 [15:49<03:09,  2.28s/it, loss=3.73]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every spoon']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every spoon']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  84%|████████▎ | 418/500 [15:52<03:06,  2.28s/it, loss=0.268]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment parking meter']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment parking meter']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  84%|████████▍ | 419/500 [15:54<03:04,  2.28s/it, loss=1.98] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment cow']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment cow']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  84%|████████▍ | 420/500 [15:56<03:01,  2.27s/it, loss=3.03]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment spoon']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment spoon']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  84%|████████▍ | 421/500 [15:58<03:00,  2.29s/it, loss=0.189]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all blue toilet in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all blue toilet in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  84%|████████▍ | 422/500 [16:01<02:58,  2.29s/it, loss=0.558]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every circular person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every circular person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  85%|████████▍ | 423/500 [16:03<02:55,  2.28s/it, loss=1.4]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  85%|████████▍ | 424/500 [16:05<02:53,  2.28s/it, loss=3.15]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment tall horse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment tall horse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  85%|████████▌ | 425/500 [16:08<02:51,  2.28s/it, loss=0.98]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all oval cat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all oval cat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  85%|████████▌ | 426/500 [16:10<02:49,  2.29s/it, loss=2.94]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every clock']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every clock']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  85%|████████▌ | 427/500 [16:12<02:46,  2.28s/it, loss=3.46]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bowl in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bowl in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  86%|████████▌ | 428/500 [16:14<02:43,  2.28s/it, loss=1.84]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all thin book']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all thin book']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  86%|████████▌ | 429/500 [16:17<02:41,  2.28s/it, loss=1.23]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all round person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all round person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  86%|████████▌ | 430/500 [16:19<02:39,  2.28s/it, loss=2.29]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all sheep regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all sheep regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  86%|████████▌ | 431/500 [16:21<02:37,  2.29s/it, loss=0.0656]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment silver zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment silver zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  86%|████████▋ | 432/500 [16:23<02:35,  2.29s/it, loss=1.23]  ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all bench']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all bench']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  87%|████████▋ | 433/500 [16:26<02:33,  2.28s/it, loss=1.17]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all black sink regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all black sink regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  87%|████████▋ | 434/500 [16:28<02:30,  2.28s/it, loss=1.31]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment yellow person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment yellow person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  87%|████████▋ | 435/500 [16:30<02:28,  2.28s/it, loss=0.966]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all airplane regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all airplane regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  87%|████████▋ | 436/500 [16:33<02:25,  2.27s/it, loss=1.06] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every gray cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every gray cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  87%|████████▋ | 437/500 [16:35<02:23,  2.27s/it, loss=1.39]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all cat']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all cat']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  88%|████████▊ | 438/500 [16:37<02:21,  2.28s/it, loss=0.995]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all giraffe objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all giraffe objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  88%|████████▊ | 439/500 [16:39<02:18,  2.28s/it, loss=1.68] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment zebra']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment zebra']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  88%|████████▊ | 440/500 [16:42<02:16,  2.27s/it, loss=2.19]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all train in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all train in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  88%|████████▊ | 441/500 [16:44<02:14,  2.28s/it, loss=2.44]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment sheep']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment sheep']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  88%|████████▊ | 442/500 [16:46<02:12,  2.28s/it, loss=1.12]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all pink potted plant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all pink potted plant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  89%|████████▊ | 443/500 [16:49<02:09,  2.28s/it, loss=0.259]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all potted plant in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all potted plant in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  89%|████████▉ | 444/500 [16:51<02:07,  2.28s/it, loss=0.0902]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all giraffe in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all giraffe in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  89%|████████▉ | 445/500 [16:53<02:05,  2.28s/it, loss=0.466] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  89%|████████▉ | 446/500 [16:55<02:03,  2.28s/it, loss=0.145]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment wine glass']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment wine glass']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  89%|████████▉ | 447/500 [16:58<02:00,  2.28s/it, loss=1.52] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all gray person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all gray person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  90%|████████▉ | 448/500 [17:00<01:58,  2.28s/it, loss=5.01]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all green person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all green person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  90%|████████▉ | 449/500 [17:02<01:56,  2.28s/it, loss=7.87]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all train in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all train in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  90%|█████████ | 450/500 [17:04<01:53,  2.28s/it, loss=3.41]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all purple person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all purple person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  90%|█████████ | 451/500 [17:07<01:51,  2.28s/it, loss=0.561]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all oval umbrella objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all oval umbrella objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  90%|█████████ | 452/500 [17:09<01:49,  2.28s/it, loss=1.19] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  91%|█████████ | 453/500 [17:11<01:47,  2.28s/it, loss=3.61]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all cow objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all cow objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  91%|█████████ | 454/500 [17:14<01:44,  2.28s/it, loss=0.386]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all square toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all square toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  91%|█████████ | 455/500 [17:16<01:42,  2.28s/it, loss=0.116]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment airplane']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment airplane']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  91%|█████████ | 456/500 [17:18<01:40,  2.28s/it, loss=4.92] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all cow regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all cow regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  91%|█████████▏| 457/500 [17:20<01:38,  2.28s/it, loss=1.44]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all tall dog objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all tall dog objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  92%|█████████▏| 458/500 [17:23<01:35,  2.28s/it, loss=0.314]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all cat from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all cat from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  92%|█████████▏| 459/500 [17:25<01:33,  2.28s/it, loss=2.03] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all circular sink objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all circular sink objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  92%|█████████▏| 460/500 [17:27<01:31,  2.28s/it, loss=0.316]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  92%|█████████▏| 461/500 [17:30<01:29,  2.28s/it, loss=0.375]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all small person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all small person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  92%|█████████▏| 462/500 [17:32<01:26,  2.29s/it, loss=0.139]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every triangular potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every triangular potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  93%|█████████▎| 463/500 [17:34<01:24,  2.28s/it, loss=5.24] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all bird regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all bird regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  93%|█████████▎| 464/500 [17:36<01:22,  2.28s/it, loss=1.14]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all person from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all person from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  93%|█████████▎| 465/500 [17:39<01:19,  2.28s/it, loss=0.729]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  93%|█████████▎| 466/500 [17:41<01:17,  2.28s/it, loss=3]    ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  93%|█████████▎| 467/500 [17:43<01:15,  2.28s/it, loss=6.67]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all elephant from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all elephant from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  94%|█████████▎| 468/500 [17:46<01:12,  2.28s/it, loss=1.87]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all zebra objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all zebra objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  94%|█████████▍| 469/500 [17:48<01:10,  2.28s/it, loss=1.43]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment silver person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment silver person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  94%|█████████▍| 470/500 [17:50<01:08,  2.28s/it, loss=2.67]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all oval banana in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all oval banana in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  94%|█████████▍| 471/500 [17:52<01:06,  2.29s/it, loss=3.13]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  94%|█████████▍| 472/500 [17:55<01:04,  2.29s/it, loss=1.55]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment tall traffic light']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment tall traffic light']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  95%|█████████▍| 473/500 [17:57<01:01,  2.29s/it, loss=0.146]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all blue person in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all blue person in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  95%|█████████▍| 474/500 [17:59<00:59,  2.29s/it, loss=1.39] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  95%|█████████▌| 475/500 [18:02<00:57,  2.29s/it, loss=3.24]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment potted plant']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment potted plant']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  95%|█████████▌| 476/500 [18:04<00:54,  2.28s/it, loss=4.08]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all large cow in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all large cow in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  95%|█████████▌| 477/500 [18:06<00:52,  2.29s/it, loss=2.97]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every dog']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every dog']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  96%|█████████▌| 478/500 [18:08<00:50,  2.29s/it, loss=0.121]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every tie']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every tie']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  96%|█████████▌| 479/500 [18:11<00:47,  2.29s/it, loss=0.204]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all suitcase']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all suitcase']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  96%|█████████▌| 480/500 [18:13<00:45,  2.28s/it, loss=3.29] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  96%|█████████▌| 481/500 [18:15<00:43,  2.29s/it, loss=1.15]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment round bird']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment round bird']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  96%|█████████▋| 482/500 [18:18<00:41,  2.29s/it, loss=0.639]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all giraffe from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all giraffe from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  97%|█████████▋| 483/500 [18:20<00:38,  2.29s/it, loss=2.97] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all bottle in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all bottle in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  97%|█████████▋| 484/500 [18:22<00:36,  2.29s/it, loss=0.94]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['extract all cow from the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['extract all cow from the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  97%|█████████▋| 485/500 [18:24<00:34,  2.28s/it, loss=3.33]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['detect and segment car']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['detect and segment car']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  97%|█████████▋| 486/500 [18:27<00:31,  2.28s/it, loss=3.16]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all person']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all person']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  97%|█████████▋| 487/500 [18:29<00:29,  2.28s/it, loss=2.8] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment any object']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment any object']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  98%|█████████▊| 488/500 [18:31<00:27,  2.29s/it, loss=0.17]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 1, 2])\n[DEBUG] point_labels shape: torch.Size([1, 1])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 2, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment bear']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment bear']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  98%|█████████▊| 489/500 [18:34<00:25,  2.29s/it, loss=1.09]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all person regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all person regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  98%|█████████▊| 490/500 [18:36<00:22,  2.29s/it, loss=2.05]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment black banana']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment black banana']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  98%|█████████▊| 491/500 [18:38<00:20,  2.29s/it, loss=0.515]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['identify and segment oval toilet']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['identify and segment oval toilet']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  98%|█████████▊| 492/500 [18:40<00:18,  2.29s/it, loss=2.32] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all black suitcase regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all black suitcase regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  99%|█████████▊| 493/500 [18:43<00:16,  2.29s/it, loss=1.44]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all horse objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all horse objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  99%|█████████▉| 494/500 [18:45<00:13,  2.29s/it, loss=0.396]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment every mouse']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment every mouse']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  99%|█████████▉| 495/500 [18:47<00:11,  2.28s/it, loss=0.095]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['highlight all zebra regions']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['highlight all zebra regions']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  99%|█████████▉| 496/500 [18:50<00:09,  2.28s/it, loss=2.07] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['segment all giraffe']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['segment all giraffe']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  99%|█████████▉| 497/500 [18:52<00:06,  2.28s/it, loss=1.16]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|█████████▉| 498/500 [18:54<00:04,  2.28s/it, loss=1.85]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['find all brown car in the image']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['find all brown car in the image']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|█████████▉| 499/500 [18:56<00:02,  2.28s/it, loss=0.709]","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\n[DEBUG] raw task_description type: <class 'list'>, value: ['locate all person objects']\n[DEBUG] converted task_descriptions type: <class 'list'> value: ['locate all person objects']\nLoRA weights from hypernetwork:\n  • output_hypernetworks_mlps.0.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.0.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.1.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.1.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.2.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.2.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • output_hypernetworks_mlps.3.layers.0.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.0.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.1.lora_B provided → (1, 4, 256)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_A provided → (1, 256, 4)  (numel=1024)\n  • output_hypernetworks_mlps.3.layers.2.lora_B provided → (1, 4, 32)  (numel=128)\n  • iou_prediction_head.layers.0.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.0.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.1.lora_B      provided → (1, 4, 256)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_A      provided → (1, 256, 4)  (numel=1024)\n  • iou_prediction_head.layers.2.lora_B      provided → (1, 4, 4)  (numel=16)\n  → total provided params: 26128\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 500/500 [18:59<00:00,  2.28s/it, loss=1.48] ","output_type":"stream"},{"name":"stdout","text":"[DEBUG] image_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] point_coords shape: torch.Size([1, 5, 2])\n[DEBUG] point_labels shape: torch.Size([1, 5])\n[DEBUG] sparse_embeddings shape: torch.Size([1, 6, 256])\n[DEBUG] dense_embeddings shape: torch.Size([1, 256, 64, 64])\n[DEBUG] image_pe shape: torch.Size([1, 256, 64, 64])\n[DEBUG] dense_embeddings final shape: torch.Size([1, 256, 64, 64])\nEpoch 2/2, Average Loss: 1.7307\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":" ✔️Saved checkpoint to /mnt/data/checkpoints/checkpoint_epoch_1.pth\nTraining completed!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from IPython.display import HTML, FileLink\n\ndisplay(HTML('<a href=\"checkpoints.zip\" download>⬇️ Download checkpoints.zip</a>'))\n\n#link to the SAM backbone checkpoint\ndisplay(HTML('<a href=\"sam_vit_h_4b8939.pth\" download>⬇️ Download sam_vit_h_4b8939.pth</a>'))\n\n#alternative\nprint(\"Or use FileLink widgets below:\")\ndisplay(FileLink('checkpoints.zip'))\ndisplay(FileLink('sam_vit_h_4b8939.pth'))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T06:24:14.006876Z","iopub.execute_input":"2025-07-19T06:24:14.007406Z","iopub.status.idle":"2025-07-19T06:24:14.017674Z","shell.execute_reply.started":"2025-07-19T06:24:14.007382Z","shell.execute_reply":"2025-07-19T06:24:14.016991Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a href=\"checkpoints.zip\" download>⬇️ Download checkpoints.zip</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a href=\"sam_vit_h_4b8939.pth\" download>⬇️ Download sam_vit_h_4b8939.pth</a>"},"metadata":{}},{"name":"stdout","text":"Or use FileLink widgets below:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/checkpoints.zip","text/html":"<a href='checkpoints.zip' target='_blank'>checkpoints.zip</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/sam_vit_h_4b8939.pth","text/html":"<a href='sam_vit_h_4b8939.pth' target='_blank'>sam_vit_h_4b8939.pth</a><br>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}